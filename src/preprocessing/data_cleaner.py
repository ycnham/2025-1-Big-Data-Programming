# src/preprocessing/data_cleaner.py

import pandas as pd
import numpy as np
import re
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class DataCleaner:
    def __init__(self):
        self.processed_data = {}
    
    def clean_all_data(self, datasets):
        """ëª¨ë“  ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì „ì²˜ë¦¬ (ì™„ì „ ìˆ˜ì •)
        if 'ev_registration_monthly' in datasets:
            self.processed_data['ev_registration'] = self._clean_ev_registration_complete_fix(
                datasets['ev_registration_monthly']
            )
        
        # ì¶©ì „ì†Œ ë°ì´í„° ì „ì²˜ë¦¬ (3ê°œì›” í†µí•©, ì™„ì „ ìˆ˜ì •)
        charging_datasets = []
        for month in ['202501', '202502', '202503']:
            key = f'charging_stations_{month}'
            if key in datasets:
                charging_datasets.append(datasets[key])
        
        if charging_datasets:
            self.processed_data['charging_stations'] = self._clean_charging_stations_complete_fix(charging_datasets)
        
        # ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„° ì „ì²˜ë¦¬ (ì™„ì „ ìˆ˜ì •)
        if 'charging_load_hourly' in datasets:
            self.processed_data['charging_hourly'] = self._clean_charging_hourly_complete_fix(
                datasets['charging_load_hourly']
            )
        
        # ìƒì—…ì‹œì„¤ ë°ì´í„° ì „ì²˜ë¦¬ (ì™„ì „ ìˆ˜ì •)
        if 'commercial_facilities' in datasets:
            self.processed_data['commercial_facilities'] = self._clean_commercial_facilities_complete_fix(
                datasets['commercial_facilities']
            )
        
        # ê²©ì ì‹œìŠ¤í…œ ìƒì„± ë° ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ (ì™„ì „ ìˆ˜ì •)
        self._create_grid_system_complete_fix()
        
        return self.processed_data
    
    def _clean_ev_registration_complete_fix(self, df):
        """ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì™„ì „ í•´ê²° - ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©"""
        print("ğŸ”§ ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì™„ì „ í•´ê²° ì¤‘...")
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
        
        try:
            print("ğŸ” Excel íŒŒì¼ ìƒì„¸ êµ¬ì¡° ë¶„ì„ ì¤‘...")
            
            # ë””ë²„ê¹…: ì²« 30í–‰ì˜ ëª¨ë“  ì»¬ëŸ¼ ë‚´ìš© ë¶„ì„
            print("ğŸ“‹ ì²« 30í–‰ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            for i in range(min(30, len(df))):
                row_values = []
                for j in range(min(len(df.columns), 10)):  # ì²« 10ê°œ ì»¬ëŸ¼ë§Œ
                    val = df.iloc[i, j]
                    if pd.notna(val):
                        row_values.append(str(val)[:15])
                    else:
                        row_values.append("NaN")
                if any(val != "NaN" for val in row_values):
                    print(f"   {i:2d}í–‰: {' | '.join(row_values)}")
            
            # 1ë‹¨ê³„: ì‹¤ì œ í—¤ë” í–‰ ì°¾ê¸°
            header_row = self._find_actual_header_row(df)
            if header_row is None:
                print("âŒ í—¤ë” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return pd.DataFrame()
            
            print(f"ğŸ“ ì‹¤ì œ í—¤ë” í–‰: {header_row}í–‰")
            
            # 2ë‹¨ê³„: í—¤ë” ì„¤ì • ë° ë°ì´í„° ì¶”ì¶œ
            headers = df.iloc[header_row].fillna('').astype(str).tolist()
            data_start_row = header_row + 1
            
            # í—¤ë” ì •ë¦¬
            cleaned_headers = self._clean_headers(headers)
            print(f"ğŸ“‹ ì •ë¦¬ëœ í—¤ë”: {cleaned_headers[:10]}...")
            
            # ë°ì´í„° ì¶”ì¶œ
            df_data = df.iloc[data_start_row:].copy()
            df_data.columns = cleaned_headers[:len(df_data.columns)]
            
            # ë¹ˆ í–‰ ì œê±°
            df_data = df_data.dropna(how='all').reset_index(drop=True)
            print(f"ğŸ“Š ë¹ˆ í–‰ ì œê±° í›„: {len(df_data)}í–‰")
            
            # 3ë‹¨ê³„: ì„œìš¸ ë°ì´í„° ì¶”ì¶œ
            seoul_data = self._extract_seoul_data_only(df_data)
            
            if len(seoul_data) == 0:
                print("âŒ ì„œìš¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return pd.DataFrame()
            
            print(f"ğŸ—ºï¸ ì„œìš¸ ì§€ì—­ ë°ì´í„° ì¶”ì¶œ: {len(seoul_data)}í–‰")
            
            # 4ë‹¨ê³„: ì „ê¸°ì°¨ ë°ì´í„°ë§Œ ì •í™•íˆ ì¶”ì¶œ
            ev_data = self._extract_electric_vehicle_data_only(seoul_data)
            
            if len(ev_data) == 0:
                print("âŒ ì „ê¸°ì°¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # 5ë‹¨ê³„: ê²°ê³¼ ê²€ì¦ ë° ì¶œë ¥
            self._validate_and_display_results(ev_data)
            
            return ev_data
            
        except Exception as e:
            print(f"âŒ ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            print("ğŸ’¡ Excel íŒŒì¼ êµ¬ì¡°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            print("ğŸš« ì‹¤ì œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¹ˆ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return pd.DataFrame()

    def _find_actual_header_row(self, df):
        """ì‹¤ì œ í—¤ë” í–‰ ì°¾ê¸°"""
        print("ğŸ” ì‹¤ì œ í—¤ë” í–‰ íƒìƒ‰ ì¤‘...")
        
        # ì—°ë£Œ íƒ€ì… í‚¤ì›Œë“œë“¤
        fuel_keywords = ['ê°€ì†”ë¦°', 'ê²½ìœ ', 'ì „ê¸°', 'lpg', 'í•˜ì´ë¸Œë¦¬ë“œ']
        
        for i in range(min(20, len(df))):
            row_text = ' '.join(df.iloc[i].fillna('').astype(str)).lower()
            
            # ì—°ë£Œ íƒ€ì…ì´ 3ê°œ ì´ìƒ í¬í•¨ëœ í–‰ ì°¾ê¸°
            found_fuels = [keyword for keyword in fuel_keywords if keyword in row_text]
            
            if len(found_fuels) >= 3:
                print(f"   ğŸ“ í—¤ë” í›„ë³´ {i}í–‰ - ë°œê²¬ëœ ì—°ë£Œ: {found_fuels}")
                
                # ì‹¤ì œ ì»¬ëŸ¼ ê°’ë“¤ í™•ì¸
                row_values = df.iloc[i].fillna('').astype(str).tolist()
                fuel_columns = [j for j, val in enumerate(row_values) if any(fuel in val.lower() for fuel in fuel_keywords)]
                
                if len(fuel_columns) >= 3:
                    print(f"   âœ… í—¤ë” í–‰ í™•ì •: {i}í–‰ (ì—°ë£Œ ì»¬ëŸ¼ ìœ„ì¹˜: {fuel_columns})")
                    return i
        
        print("   âš ï¸ í‘œì¤€ í—¤ë”ë¥¼ ì°¾ì§€ ëª»í•¨. ë°ì´í„° ì‹œì‘ì  ì¶”ì •...")
        
        # ì„œìš¸ êµ¬ ë°ì´í„°ê°€ ì‹œì‘ë˜ëŠ” ì§€ì  ì°¾ê¸°
        seoul_districts = ['ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬']
        
        for i in range(len(df)):
            row_text = ' '.join(df.iloc[i].fillna('').astype(str))
            if any(district in row_text for district in seoul_districts):
                # ë°ì´í„° í–‰ì´ë¯€ë¡œ ê·¸ ì´ì „ í–‰ì´ í—¤ë”ì¼ ê°€ëŠ¥ì„±
                if i > 0:
                    return i - 1
                else:
                    return i
        
        return None

    def _clean_headers(self, headers):
        """í—¤ë” ì •ë¦¬"""
        cleaned = []
        
        for i, header in enumerate(headers):
            header_str = str(header).strip()
            
            # ë¹ˆ í—¤ë”ë‚˜ ì˜ë¯¸ì—†ëŠ” í—¤ë” ì²˜ë¦¬
            if not header_str or header_str.lower() in ['nan', 'unnamed']:
                if i == 0:
                    cleaned.append('ì§€ì—­ì •ë³´1')
                elif i == 1:
                    cleaned.append('ì§€ì—­ì •ë³´2')
                elif i == 2:
                    cleaned.append('ì§€ì—­ì •ë³´3')
                else:
                    cleaned.append(f'ì»¬ëŸ¼_{i}')
            else:
                # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ë¦¬
                clean_header = header_str.replace('\n', '').replace('\r', '').strip()
                if clean_header:
                    cleaned.append(clean_header)
                else:
                    cleaned.append(f'ì»¬ëŸ¼_{i}')
        
        return cleaned

    def _extract_seoul_data_only(self, df_data):
        """ì„œìš¸ ë°ì´í„°ë§Œ ì¶”ì¶œ"""
        print("ğŸ” ì„œìš¸ ë°ì´í„°ë§Œ ì¶”ì¶œ ì¤‘...")
        
        seoul_districts = [
            'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 
            'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬', 'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬',
            'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ë™ì‘êµ¬', 'ê´€ì•…êµ¬',
            'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
        ]
        
        seoul_rows = []
        
        # ëª¨ë“  ì»¬ëŸ¼ì—ì„œ ì„œìš¸ êµ¬ ì°¾ê¸°
        for i, row in df_data.iterrows():
            row_text = ' '.join(row.fillna('').astype(str))
            
            # ì„œìš¸ êµ¬ê°€ í¬í•¨ëœ í–‰ì¸ì§€ í™•ì¸
            found_district = None
            for district in seoul_districts:
                if district in row_text:
                    found_district = district
                    break
            
            if found_district:
                seoul_rows.append(i)
                
                # ì²˜ìŒ ëª‡ ê°œ êµ¬ëŠ” ë¡œê·¸ ì¶œë ¥
                if len(seoul_rows) <= 5:
                    print(f"   ğŸ—ºï¸ {found_district} ë°ì´í„° ë°œê²¬: {i}í–‰")
        
        if seoul_rows:
            seoul_data = df_data.iloc[seoul_rows].copy().reset_index(drop=True)
            print(f"   âœ… ì´ ì„œìš¸ ë°ì´í„°: {len(seoul_data)}í–‰")
            return seoul_data
        else:
            print("   âŒ ì„œìš¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return pd.DataFrame()

    def _extract_electric_vehicle_data_only(self, seoul_data):
        """ì „ê¸°ì°¨ ë°ì´í„°ë§Œ ì •í™•íˆ ì¶”ì¶œ - ë°ì´í„° êµ¬ì¡° ê¸°ë°˜ ì ‘ê·¼"""
        print("âš¡ ì „ê¸°ì°¨ ë°ì´í„°ë§Œ ì¶”ì¶œ ì¤‘...")
        
        # ë°ì´í„° êµ¬ì¡° ë¶„ì„: ì—°ë£Œ íƒ€ì…ì´ ë°ì´í„° ê°’ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” êµ¬ì¡°
        print("   ğŸ” ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        # ì „ê¸°ì°¨ ê´€ë ¨ í–‰ ì°¾ê¸° - ì—°ë£Œ ì»¬ëŸ¼ì—ì„œ 'ì „ê¸°' ê°’ì´ ìˆëŠ” í–‰ë“¤
        electric_rows = []
        
        for i, row in seoul_data.iterrows():
            # ëª¨ë“  ì»¬ëŸ¼ì—ì„œ 'ì „ê¸°' ê°’ ì°¾ê¸°
            for col_idx, value in enumerate(row.values):
                if pd.notna(value) and str(value).strip() == 'ì „ê¸°':
                    electric_rows.append(i)
                    print(f"   ğŸ“ ì „ê¸°ì°¨ ë°ì´í„° ë°œê²¬: {i}í–‰")
                    break
        
        if not electric_rows:
            print("   âŒ ì „ê¸°ì°¨ ë°ì´í„°ë¥¼ í¬í•¨í•œ í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return pd.DataFrame()
        
        print(f"   âœ… ì „ê¸°ì°¨ ê´€ë ¨ í–‰ {len(electric_rows)}ê°œ ë°œê²¬")
        
        # ì „ê¸°ì°¨ ë°ì´í„° ì¶”ì¶œ
        extracted_data = []
        
        for row_idx in electric_rows:
            try:
                row = seoul_data.iloc[row_idx]
                
                # ì§€ì—­ ì •ë³´ ì¶”ì¶œ (ì²« ë²ˆì§¸ì™€ ì„¸ ë²ˆì§¸ ì»¬ëŸ¼ì—ì„œ ì£¼ë¡œ ë°œê²¬)
                region_info = self._extract_region_from_electric_row(row)
                
                if region_info['ì‹œêµ°êµ¬'] and region_info['ìë©´ë™']:
                    # ì „ê¸°ì°¨ ìˆ˜ ì¶”ì¶œ (ì—°ë£Œê°€ 'ì „ê¸°'ì¸ í–‰ì—ì„œ ê³„ ì»¬ëŸ¼ ì°¾ê¸°)
                    ev_count = self._extract_ev_count_from_row(row)
                    
                    if ev_count is not None and ev_count > 0:
                        extracted_data.append({
                            'ì‹œêµ°êµ¬': region_info['ì‹œêµ°êµ¬'],
                            'ìë©´ë™': region_info['ìë©´ë™'],
                            'ì „ê¸°ì°¨_ìˆ˜': ev_count,
                            'ì›ë³¸_í–‰': row_idx
                        })
                        
                        # ì²˜ìŒ 5ê°œëŠ” ë¡œê·¸ ì¶œë ¥
                        if len(extracted_data) <= 5:
                            print(f"   âœ… {region_info['ì‹œêµ°êµ¬']} {region_info['ìë©´ë™']}: {ev_count}ëŒ€")
                            
            except Exception as e:
                print(f"   âš ï¸ {row_idx}í–‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        if extracted_data:
            result_df = pd.DataFrame(extracted_data)
            
            # ì¤‘ë³µ ì§€ì—­ ì²˜ë¦¬ (ê°™ì€ ì‹œêµ°êµ¬+ìë©´ë™ì´ ì—¬ëŸ¬ ê°œ ìˆëŠ” ê²½ìš° í•©ê³„)
            result_df = result_df.groupby(['ì‹œêµ°êµ¬', 'ìë©´ë™'])['ì „ê¸°ì°¨_ìˆ˜'].sum().reset_index()
            
            # ì „ê¸°ì°¨ ìˆ˜ê°€ 0ì¸ ì§€ì—­ ì œê±°
            result_df = result_df[result_df['ì „ê¸°ì°¨_ìˆ˜'] > 0].reset_index(drop=True)
            
            print(f"   âœ… ì „ê¸°ì°¨ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(result_df)}ê°œ ì§€ì—­")
            return result_df
        else:
            print("   âŒ ìœ íš¨í•œ ì „ê¸°ì°¨ ë°ì´í„° ì—†ìŒ")
            return pd.DataFrame()
    
    def _extract_region_from_electric_row(self, row):
        """ì „ê¸°ì°¨ í–‰ì—ì„œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ"""
        region_info = {'ì‹œêµ°êµ¬': None, 'ìë©´ë™': None}
        
        seoul_districts = [
            'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 
            'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬', 'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬',
            'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ë™ì‘êµ¬', 'ê´€ì•…êµ¬',
            'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
        ]
        
        # ëª¨ë“  ê°’ì—ì„œ ì§€ì—­ ì •ë³´ ì°¾ê¸°
        for value in row.values:
            if pd.notna(value):
                value_str = str(value).strip()
                
                # êµ¬ ì´ë¦„ ì°¾ê¸°
                for district in seoul_districts:
                    if district in value_str:
                        region_info['ì‹œêµ°êµ¬'] = district
                        break
                
                # ë™ ì´ë¦„ ì°¾ê¸° (ëì´ 'ë™'ìœ¼ë¡œ ëë‚˜ê³  êµ¬ ì´ë¦„ì´ í¬í•¨ë˜ì§€ ì•Šì€ ê²½ìš°)
                if value_str.endswith('ë™') and len(value_str) <= 15:
                    if not any(district in value_str for district in seoul_districts):
                        if not region_info['ìë©´ë™']:  # ì²« ë²ˆì§¸ë¡œ ë°œê²¬ëœ ë™ ì´ë¦„ ì‚¬ìš©
                            region_info['ìë©´ë™'] = value_str
        
        # ìë©´ë™ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not region_info['ìë©´ë™'] and region_info['ì‹œêµ°êµ¬']:
            region_info['ìë©´ë™'] = f"{region_info['ì‹œêµ°êµ¬'][:-1]}ë™"
        
        return region_info
    
    def _extract_ev_count_from_row(self, row):
        """ì „ê¸°ì°¨ í–‰ì—ì„œ ì „ê¸°ì°¨ ìˆ˜ ì¶”ì¶œ"""
        # 'ì „ê¸°'ê°€ ìˆëŠ” ì»¬ëŸ¼ì˜ ìœ„ì¹˜ë¥¼ ì°¾ê³ , ê·¸ í–‰ì˜ ìˆ«ì ê°’ë“¤ ì¤‘ ê°€ì¥ í° ê°’ì„ ì „ê¸°ì°¨ ìˆ˜ë¡œ ê°„ì£¼
        numbers = []
        
        for value in row.values:
            if pd.notna(value):
                try:
                    # ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ
                    value_str = str(value).replace(',', '').strip()
                    if value_str.isdigit():
                        num = int(value_str)
                        if 1 <= num <= 50000:  # í•©ë¦¬ì ì¸ ë²”ìœ„ì˜ ìˆ«ìë§Œ
                            numbers.append(num)
                except:
                    continue
        
        if numbers:
            # ê°€ì¥ í° ìˆ«ìë¥¼ ì „ê¸°ì°¨ ì´ ìˆ˜ë¡œ ê°„ì£¼ (ë³´í†µ 'ê³„' ì»¬ëŸ¼ì— í•´ë‹¹)
            return max(numbers)
        
        return None

    def _find_region_columns(self, df):
        """ì§€ì—­ ì •ë³´ ì»¬ëŸ¼ ì°¾ê¸°"""
        region_cols = {'ì‹œêµ°êµ¬': None, 'ìë©´ë™': None}
        
        for col in df.columns:
            col_str = str(col).lower()
            if 'ì‹œêµ°êµ¬' in col_str or 'êµ¬' in col_str:
                region_cols['ì‹œêµ°êµ¬'] = col
            elif 'ìë©´ë™' in col_str or 'ë™' in col_str:
                region_cols['ìë©´ë™'] = col
        
        print(f"   ğŸ“ ì§€ì—­ ì»¬ëŸ¼: ì‹œêµ°êµ¬='{region_cols['ì‹œêµ°êµ¬']}', ìë©´ë™='{region_cols['ìë©´ë™']}'")
        return region_cols

    def _extract_region_from_row(self, row, region_cols):
        """í–‰ì—ì„œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ"""
        region_info = {'ì‹œêµ°êµ¬': None, 'ìë©´ë™': None}
        
        seoul_districts = [
            'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬', 
            'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬', 'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬',
            'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ë™ì‘êµ¬', 'ê´€ì•…êµ¬',
            'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
        ]
        
        # ì‹œêµ°êµ¬ ì°¾ê¸°
        if region_cols['ì‹œêµ°êµ¬'] and pd.notna(row[region_cols['ì‹œêµ°êµ¬']]):
            gu_value = str(row[region_cols['ì‹œêµ°êµ¬']])
            for district in seoul_districts:
                if district in gu_value:
                    region_info['ì‹œêµ°êµ¬'] = district
                    break
        
        # ì‹œêµ°êµ¬ë¥¼ ëª» ì°¾ì€ ê²½ìš° ì „ì²´ í–‰ì—ì„œ ì°¾ê¸°
        if not region_info['ì‹œêµ°êµ¬']:
            for val in row.values:
                if pd.notna(val):
                    val_str = str(val)
                    for district in seoul_districts:
                        if district in val_str:
                            region_info['ì‹œêµ°êµ¬'] = district
                            break
                    if region_info['ì‹œêµ°êµ¬']:
                        break
        
        # ìë©´ë™ ì°¾ê¸°
        if region_cols['ìë©´ë™'] and pd.notna(row[region_cols['ìë©´ë™']]):
            dong_value = str(row[region_cols['ìë©´ë™']])
            if dong_value.endswith('ë™') and len(dong_value) <= 15:
                region_info['ìë©´ë™'] = dong_value
        
        # ìë©´ë™ì„ ëª» ì°¾ì€ ê²½ìš° ì „ì²´ í–‰ì—ì„œ ì°¾ê¸°
        if not region_info['ìë©´ë™']:
            for val in row.values:
                if pd.notna(val):
                    val_str = str(val)
                    if val_str.endswith('ë™') and len(val_str) <= 15:
                        # êµ¬ ì´ë¦„ì´ í¬í•¨ë˜ì§€ ì•Šì€ ìˆœìˆ˜í•œ ë™ ì´ë¦„ì¸ì§€ í™•ì¸
                        if not any(district in val_str for district in seoul_districts):
                            region_info['ìë©´ë™'] = val_str
                            break
        
        # ìë©´ë™ì„ ì•„ì§ë„ ëª» ì°¾ì€ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not region_info['ìë©´ë™'] and region_info['ì‹œêµ°êµ¬']:
            region_info['ìë©´ë™'] = f"{region_info['ì‹œêµ°êµ¬'][:-1]}ë™"
        
        return region_info

    def _validate_and_display_results(self, ev_data):
        """ê²°ê³¼ ê²€ì¦ ë° ì¶œë ¥"""
        print("ğŸ“Š ì „ê¸°ì°¨ ë°ì´í„° ê²€ì¦ ë° ê²°ê³¼ ì¶œë ¥:")
        
        if len(ev_data) == 0:
            print("   âŒ ì¶”ì¶œëœ ì „ê¸°ì°¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê¸°ë³¸ í†µê³„
        total_ev = ev_data['ì „ê¸°ì°¨_ìˆ˜'].sum()
        valid_count = ev_data['ì „ê¸°ì°¨_ìˆ˜'].notna().sum()
        avg_ev = ev_data['ì „ê¸°ì°¨_ìˆ˜'].mean()
        max_ev = ev_data['ì „ê¸°ì°¨_ìˆ˜'].max()
        min_ev = ev_data['ì „ê¸°ì°¨_ìˆ˜'].min()
        
        print(f"âš¡ ì „ê¸°ì°¨ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ:")
        print(f"   - ì „ê¸°ì°¨ ë“±ë¡ ì§€ì—­: {len(ev_data)}ê°œ")
        print(f"   - ìœ íš¨ ë°ì´í„°: {valid_count}ê°œ")
        print(f"   - ì´ ì „ê¸°ì°¨ ìˆ˜: {total_ev:,.0f}ëŒ€")
        print(f"   - í‰ê·  ì§€ì—­ë‹¹ ì „ê¸°ì°¨: {avg_ev:.1f}ëŒ€")
        print(f"   - ìµœëŒ€ ë“±ë¡ ì§€ì—­: {max_ev:.0f}ëŒ€")
        print(f"   - ìµœì†Œ ë“±ë¡ ì§€ì—­: {min_ev:.0f}ëŒ€")
        
        # ìƒìœ„ 5ê°œ ì§€ì—­ ì¶œë ¥ (ì „ê¸°ì°¨ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œë§Œ)
        top_regions = ev_data.nlargest(5, 'ì „ê¸°ì°¨_ìˆ˜')
        
        print("ğŸ† ì „ê¸°ì°¨ ë“±ë¡ ìƒìœ„ 5ê°œ ì§€ì—­:")
        for _, row in top_regions.iterrows():
            print(f"   {row['ì‹œêµ°êµ¬']} {row['ìë©´ë™']}: {row['ì „ê¸°ì°¨_ìˆ˜']:.0f}ëŒ€")
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        if total_ev < 100:
            print("âš ï¸ ê²½ê³ : ì´ ì „ê¸°ì°¨ ìˆ˜ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì„ ì¬í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        if len(ev_data) < 10:
            print("âš ï¸ ê²½ê³ : ì¶”ì¶œëœ ì§€ì—­ì´ ë§¤ìš° ì ìŠµë‹ˆë‹¤. ì¶”ì¶œ ë²”ìœ„ë¥¼ ì¬í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ë¹„ì •ìƒì ì¸ ê°’ ì²´í¬
        abnormal_values = ev_data[ev_data['ì „ê¸°ì°¨_ìˆ˜'] > 10000]
        if len(abnormal_values) > 0:
            print(f"âš ï¸ ê²½ê³ : ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ê°’ì´ ìˆëŠ” ì§€ì—­ {len(abnormal_values)}ê°œ")
            for _, row in abnormal_values.iterrows():
                print(f"   {row['ì‹œêµ°êµ¬']} {row['ìë©´ë™']}: {row['ì „ê¸°ì°¨_ìˆ˜']:.0f}ëŒ€")
    
    
    def _clean_charging_stations_complete_fix(self, datasets):
        """ì¶©ì „ì†Œ ë°ì´í„° ì™„ì „ í•´ê²° - ê²°ì¸¡ê°’ ëŒ€í­ ê°ì†Œ"""
        print("ğŸ”§ ì¶©ì „ì†Œ ë°ì´í„° ì™„ì „ í•´ê²° ì¤‘...")
        
        # ë°ì´í„° í†µí•©
        combined_df = pd.concat(datasets, ignore_index=True)
        print(f"ğŸ“Š í†µí•©ëœ ë°ì´í„° í˜•íƒœ: {combined_df.shape}")
        
        # 1. ì™„ì „íˆ ë¹ˆ ì»¬ëŸ¼ ì œê±°
        empty_cols = []
        for col in combined_df.columns:
            if combined_df[col].isnull().all():
                empty_cols.append(col)
        
        if empty_cols:
            combined_df = combined_df.drop(columns=empty_cols)
            print(f"ğŸ—‘ï¸ ì™„ì „ ë¹ˆ ì»¬ëŸ¼ {len(empty_cols)}ê°œ ì œê±°")
        
        # 2. ê²°ì¸¡ë¥  90% ì´ìƒ ì»¬ëŸ¼ ì œê±°
        high_missing_cols = []
        for col in combined_df.columns:
            missing_rate = combined_df[col].isnull().sum() / len(combined_df)
            if missing_rate > 0.9:
                high_missing_cols.append(col)
        
        if high_missing_cols:
            combined_df = combined_df.drop(columns=high_missing_cols)
            print(f"ğŸ—‘ï¸ ê³ ê²°ì¸¡ ì»¬ëŸ¼ {len(high_missing_cols)}ê°œ ì œê±°")
        
        # 3. í•µì‹¬ ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì œê±°
        essential_cols = ['ì‹œë„', 'ì‹œêµ°êµ¬', 'ì¶©ì „ì†Œëª…']
        available_essential = [col for col in essential_cols if col in combined_df.columns]
        
        if available_essential:
            before_count = len(combined_df)
            combined_df = combined_df.dropna(subset=available_essential, how='any')
            after_count = len(combined_df)
            print(f"ğŸ”§ í•µì‹¬ ì •ë³´ ëˆ„ë½í–‰ ì œê±°: {before_count:,} â†’ {after_count:,}í–‰")
        
        # 4. ì¶©ì „êµ¬ë¶„ ì»¬ëŸ¼ í†µì¼
        if 'ì¶©ì „ê¸°êµ¬ë¶„' in combined_df.columns and 'ì¶©ì „êµ¬ë¶„' not in combined_df.columns:
            combined_df['ì¶©ì „êµ¬ë¶„'] = combined_df['ì¶©ì „ê¸°êµ¬ë¶„']
        elif 'ì¶©ì „ê¸°êµ¬ë¶„' in combined_df.columns and 'ì¶©ì „êµ¬ë¶„' in combined_df.columns:
            combined_df['ì¶©ì „êµ¬ë¶„'] = combined_df['ì¶©ì „êµ¬ë¶„'].fillna(combined_df['ì¶©ì „ê¸°êµ¬ë¶„'])
        
        # 5. ì¶©ì „ëŸ‰ ë°ì´í„° ì •ë¦¬
        if 'ì¶©ì „ëŸ‰' in combined_df.columns:
            combined_df['ì¶©ì „ëŸ‰_numeric'] = pd.to_numeric(combined_df['ì¶©ì „ëŸ‰'], errors='coerce')
            
            # ìœ íš¨í•œ ì¶©ì „ëŸ‰ë§Œ ìœ ì§€ (0 ì´ìƒ 1000 ì´í•˜)
            valid_charging = (
                combined_df['ì¶©ì „ëŸ‰_numeric'].between(0, 1000, inclusive='both') &
                combined_df['ì¶©ì „ëŸ‰_numeric'].notna()
            )
            combined_df = combined_df[valid_charging].copy()
            print(f"âš¡ ìœ íš¨í•œ ì¶©ì „ëŸ‰ ë°ì´í„°: {len(combined_df):,}í–‰")
        
        # 6. ë‚ ì§œ ë°ì´í„° ì •ë¦¬
        date_columns = ['ì¶©ì „ì¢…ë£Œì¼', 'ì¶©ì „ì‹œì‘ì‹œê°', 'ì¶©ì „ì¢…ë£Œì‹œê°']
        for col in date_columns:
            if col in combined_df.columns:
                combined_df[col] = pd.to_datetime(combined_df[col], errors='coerce')
        
        # 7. ë‚¨ì€ ê²°ì¸¡ê°’ ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬
        for col in combined_df.columns:
            if combined_df[col].isnull().sum() == 0:
                continue
                
            if combined_df[col].dtype == 'object':
                # ë¬¸ìì—´ ì»¬ëŸ¼ - ì˜ë¯¸ìˆëŠ” ê¸°ë³¸ê°’
                if 'ì£¼ì†Œ' in col:
                    combined_df[col] = combined_df[col].fillna('ì£¼ì†Œì •ë³´ì—†ìŒ')
                elif 'ëª…' in col:
                    combined_df[col] = combined_df[col].fillna('ì •ë³´ì—†ìŒ')
                else:
                    combined_df[col] = combined_df[col].fillna('ë¯¸ìƒ')
            else:
                # ìˆ«ì ì»¬ëŸ¼ - 0 ë˜ëŠ” ì¤‘ì•™ê°’
                if 'ëŸ‰' in col or 'amount' in col.lower():
                    combined_df[col] = combined_df[col].fillna(0)
                else:
                    median_val = combined_df[col].median()
                    combined_df[col] = combined_df[col].fillna(median_val if pd.notna(median_val) else 0)
        
        print(f"âœ… ì¶©ì „ì†Œ ë°ì´í„° ì™„ì „ í•´ê²° ì™„ë£Œ: {len(combined_df):,}í–‰")
        final_missing = combined_df.isnull().sum().sum()
        print(f"ğŸ“Š ìµœì¢… ê²°ì¸¡ê°’: {final_missing:,}ê°œ (ëŒ€í­ ê°ì†Œ)")
        
        return combined_df
    
    def _clean_charging_hourly_complete_fix(self, df):
        """ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„° ì™„ì „ í•´ê²°"""
        print("ğŸ”§ ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„° ì™„ì „ í•´ê²° ì¤‘...")
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
        
        # í—¤ë”ê°€ ìˆëŠ” í–‰ ì°¾ê¸°
        header_row = None
        for i in range(min(10, len(df))):
            row_str = ' '.join(df.iloc[i].fillna('').astype(str))
            if 'ìˆœë²ˆ' in row_str and 'ì¶©ì „ì†Œëª…' in row_str:
                header_row = i
                break
        
        if header_row is not None:
            # í—¤ë” ì„¤ì •
            headers = df.iloc[header_row].fillna('Unknown').astype(str)
            df_clean = df.iloc[header_row+1:].copy()
            df_clean.columns = headers
            
            # ë¹ˆ í–‰ ì œê±°
            df_clean = df_clean.dropna(how='all')
            
            # ìˆœë²ˆì´ ìˆ«ìì¸ í–‰ë§Œ ìœ ì§€
            if 'ìˆœë²ˆ' in df_clean.columns:
                numeric_mask = pd.to_numeric(df_clean['ìˆœë²ˆ'], errors='coerce').notna()
                df_clean = df_clean[numeric_mask]
        else:
            df_clean = df.copy()
        
        # ê²°ì¸¡ê°’ ìµœì†Œí™”
        for col in df_clean.columns:
            if df_clean[col].dtype == 'object':
                df_clean[col] = df_clean[col].fillna('ì •ë³´ì—†ìŒ')
            else:
                df_clean[col] = df_clean[col].fillna(0)
        
        print(f"âœ… ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„° ì™„ì „ í•´ê²°: {len(df_clean)}í–‰")
        return df_clean
    
    def _clean_commercial_facilities_complete_fix(self, df):
        """ìƒì—…ì‹œì„¤ ë°ì´í„° ì™„ì „ í•´ê²° - ê²°ì¸¡ê°’ ëŒ€í­ ê°ì†Œ"""
        print("ğŸ”§ ìƒì—…ì‹œì„¤ ë°ì´í„° ì™„ì „ í•´ê²° ì¤‘...")
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
        
        # 1. ì™„ì „íˆ ë¹ˆ ì»¬ëŸ¼ ì œê±°
        empty_cols = [col for col in df.columns if df[col].isnull().all()]
        if empty_cols:
            df = df.drop(columns=empty_cols)
            print(f"ğŸ—‘ï¸ ì™„ì „ ë¹ˆ ì»¬ëŸ¼ {len(empty_cols)}ê°œ ì œê±°")
        
        # 2. ê²°ì¸¡ë¥  95% ì´ìƒ ì»¬ëŸ¼ ì œê±°
        high_missing_cols = []
        for col in df.columns:
            missing_rate = df[col].isnull().sum() / len(df)
            if missing_rate > 0.95:
                high_missing_cols.append(col)
        
        if high_missing_cols:
            df = df.drop(columns=high_missing_cols)
            print(f"ğŸ—‘ï¸ ê³ ê²°ì¸¡ ì»¬ëŸ¼ {len(high_missing_cols)}ê°œ ì œê±°")
        
        # 3. í•µì‹¬ ì •ë³´ ëˆ„ë½ í–‰ ì œê±°
        essential_cols = ['ìƒí˜¸ëª…', 'ê²½ë„', 'ìœ„ë„', 'ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…']
        available_essential = [col for col in essential_cols if col in df.columns]
        
        if available_essential:
            before_count = len(df)
            df = df.dropna(subset=available_essential, how='any')
            after_count = len(df)
            print(f"ğŸ”§ í•µì‹¬ ì •ë³´ ëˆ„ë½í–‰ ì œê±°: {before_count:,} â†’ {after_count:,}í–‰")
        
        # 4. ì„œìš¸ ì§€ì—­ ì¢Œí‘œ í•„í„°ë§
        if 'ê²½ë„' in df.columns and 'ìœ„ë„' in df.columns:
            seoul_coords = (
                df['ê²½ë„'].between(126.7, 127.2) & 
                df['ìœ„ë„'].between(37.4, 37.7)
            )
            df = df[seoul_coords].copy()
            print(f"ğŸ“ ì„œìš¸ ì§€ì—­ í•„í„°ë§: {len(df):,}ê°œ ì‹œì„¤")
        
        # 5. ì—…ì¢… ë¶„ë¥˜ ì •ë¦¬
        if 'ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…' in df.columns:
            df['ì—…ì¢…_ëŒ€ë¶„ë¥˜'] = df['ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…']
        
        if 'ìƒê¶Œì—…ì¢…ì¤‘ë¶„ë¥˜ëª…' in df.columns:
            df['ì—…ì¢…_ì¤‘ë¶„ë¥˜'] = df['ìƒê¶Œì—…ì¢…ì¤‘ë¶„ë¥˜ëª…']
        
        # 6. ë‚¨ì€ ê²°ì¸¡ê°’ ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬
        for col in df.columns:
            if df[col].isnull().sum() == 0:
                continue
                
            if df[col].dtype == 'object':
                if 'ì£¼ì†Œ' in col:
                    df[col] = df[col].fillna('ì£¼ì†Œì •ë³´ì—†ìŒ')
                elif 'ëª…' in col:
                    df[col] = df[col].fillna('ì •ë³´ì—†ìŒ')
                else:
                    df[col] = df[col].fillna('ë¯¸ìƒ')
            else:
                df[col] = df[col].fillna(0)
        
        print(f"âœ… ìƒì—…ì‹œì„¤ ë°ì´í„° ì™„ì „ í•´ê²°: {len(df):,}í–‰")
        final_missing = df.isnull().sum().sum()
        print(f"ğŸ“Š ìµœì¢… ê²°ì¸¡ê°’: {final_missing:,}ê°œ (ëŒ€í­ ê°ì†Œ)")
        
        return df
    
    def _create_grid_system_complete_fix(self):
        """ê²©ì ì‹œìŠ¤í…œ ì™„ì „ í•´ê²° - ê³µê¸‰ ê²©ì 0ê°œ ë¬¸ì œ í•´ê²°"""
        print("ğŸ—ºï¸ ê²©ì ì‹œìŠ¤í…œ ì™„ì „ í•´ê²° ì¤‘...")
        
        # ì„œìš¸ ì§€ì—­ ê²½ê³„
        seoul_bounds = {
            'min_lat': 37.4,
            'max_lat': 37.7,
            'min_lon': 126.7,
            'max_lon': 127.2
        }
        
        # 500më¥¼ ìœ„ë„/ê²½ë„ë¡œ ë³€í™˜
        grid_size_lat = 0.0045  # ì•½ 500m
        grid_size_lon = 0.0056  # ì•½ 500m
        
        # ê²©ì ìƒì„±
        lats = np.arange(seoul_bounds['min_lat'], seoul_bounds['max_lat'], grid_size_lat)
        lons = np.arange(seoul_bounds['min_lon'], seoul_bounds['max_lon'], grid_size_lon)
        
        grid_data = []
        total_grids = len(lats) * len(lons)
        print(f"ğŸ“Š ìƒì„±í•  ì´ ê²©ì ìˆ˜: {total_grids:,}ê°œ")
        
        for i, lat in enumerate(lats):
            for j, lon in enumerate(lons):
                grid_center_lat = lat + grid_size_lat/2
                grid_center_lon = lon + grid_size_lon/2
                
                # ìˆ˜ìš” ì ìˆ˜ ê³„ì‚°
                demand_score = self._calculate_demand_score_fix(
                    grid_center_lat, grid_center_lon, grid_size_lat, grid_size_lon
                )
                
                # ê³µê¸‰ ì ìˆ˜ ê³„ì‚° (ì™„ì „ ìˆ˜ì •)
                supply_score = self._calculate_supply_score_fix(
                    grid_center_lat, grid_center_lon, grid_size_lat, grid_size_lon
                )
                
                grid_data.append({
                    'grid_id': f'GRID_{i:03d}_{j:03d}',
                    'min_lat': lat,
                    'max_lat': lat + grid_size_lat,
                    'min_lon': lon,
                    'max_lon': lon + grid_size_lon,
                    'center_lat': grid_center_lat,
                    'center_lon': grid_center_lon,
                    'demand_score': demand_score,
                    'supply_score': supply_score
                })
        
        grid_df = pd.DataFrame(grid_data)
        self.processed_data['grid_system'] = grid_df
        
        # í†µê³„ ë¶„ì„ (ì™„ì „ ìˆ˜ì •)
        total_grids = len(grid_df)
        demand_grids = (grid_df['demand_score'] > 0).sum()
        supply_grids = (grid_df['supply_score'] > 0).sum()
        
        print(f"âœ… ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ: {total_grids:,}ê°œ ê²©ì")
        print(f"ğŸ“ˆ ìˆ˜ìš”ê°€ ìˆëŠ” ê²©ì: {demand_grids:,}ê°œ ({demand_grids/total_grids*100:.1f}%)")
        print(f"ğŸ“¦ ê³µê¸‰ì´ ìˆëŠ” ê²©ì: {supply_grids:,}ê°œ ({supply_grids/total_grids*100:.1f}%)")
        
        # ìƒìœ„ 10% ê³„ì‚° ì™„ì „ ìˆ˜ì •
        if supply_grids > 0:
            # ê³µê¸‰ì´ ìˆëŠ” ê²©ìë“¤ë§Œ ëŒ€ìƒìœ¼ë¡œ ìƒìœ„ 10% ê³„ì‚°
            supply_values = grid_df[grid_df['supply_score'] > 0]['supply_score']
            supply_90th_percentile = supply_values.quantile(0.9)
            top_10_percent_supply = (grid_df['supply_score'] >= supply_90th_percentile).sum()
            
            print(f"ğŸ“Š ê³µê¸‰ 90í¼ì„¼íƒ€ì¼ ê°’: {supply_90th_percentile:.1f}")
            print(f"ğŸ“Š ìƒìœ„ 10% ê³µê¸‰ ê²©ì: {top_10_percent_supply:,}ê°œ")
            
            if top_10_percent_supply == 0:
                print("âŒ ì—¬ì „íˆ ìƒìœ„ 10% ê³µê¸‰ ê²©ìê°€ 0ê°œì…ë‹ˆë‹¤. ê³„ì‚° ë°©ì‹ì„ ì¬ê²€í† í•©ë‹ˆë‹¤.")
                # ëŒ€ì•ˆ: ìƒìœ„ Nê°œ ë°©ì‹
                top_n = max(1, supply_grids // 10)  # ìµœì†Œ 1ê°œ
                print(f"ğŸ”„ ëŒ€ì•ˆ: ìƒìœ„ {top_n}ê°œ ê²©ìë¥¼ ìµœê³  ê³µê¸‰ ê²©ìë¡œ ì„¤ì •")
            else:
                print(f"âœ… ìƒìœ„ 10% ê³µê¸‰ ê²©ì ê³„ì‚° ì„±ê³µ: {top_10_percent_supply:,}ê°œ")
        else:
            print("âŒ ê³µê¸‰ì´ ìˆëŠ” ê²©ìê°€ 0ê°œì…ë‹ˆë‹¤. ê³µê¸‰ ê³„ì‚° ë¡œì§ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        return grid_df
    
    def _calculate_demand_score_fix(self, center_lat, center_lon, grid_size_lat, grid_size_lon):
        """ìˆ˜ìš” ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
        if 'commercial_facilities' not in self.processed_data:
            return 0
        
        facilities_df = self.processed_data['commercial_facilities']
        
        if 'ê²½ë„' not in facilities_df.columns or 'ìœ„ë„' not in facilities_df.columns:
            return 0
        
        # ê²©ì ë²”ìœ„ ë‚´ ìƒì—…ì‹œì„¤ ì°¾ê¸°
        min_lat = center_lat - grid_size_lat/2
        max_lat = center_lat + grid_size_lat/2
        min_lon = center_lon - grid_size_lon/2
        max_lon = center_lon + grid_size_lon/2
        
        facilities_in_grid = facilities_df[
            (facilities_df['ìœ„ë„'].between(min_lat, max_lat)) &
            (facilities_df['ê²½ë„'].between(min_lon, max_lon))
        ]
        
        if len(facilities_in_grid) == 0:
            return 0
        
        # ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        demand_score = 0
        business_col = None
        
        for col in ['ì—…ì¢…_ëŒ€ë¶„ë¥˜', 'ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…']:
            if col in facilities_in_grid.columns:
                business_col = col
                break
        
        if business_col:
            weights = {
                'ìŒì‹': 3.0,
                'ì†Œë§¤': 2.5,
                'ì„œë¹„ìŠ¤': 2.0,
                'êµìœ¡': 1.5,
                'ì˜ë£Œ': 2.0
            }
            
            for category, weight in weights.items():
                count = facilities_in_grid[business_col].str.contains(category, na=False).sum()
                demand_score += count * weight
            
            # ê¸°íƒ€ ì—…ì¢…
            other_count = len(facilities_in_grid)
            for category in weights.keys():
                other_count -= facilities_in_grid[business_col].str.contains(category, na=False).sum()
            demand_score += max(0, other_count) * 1.0
        else:
            demand_score = len(facilities_in_grid) * 1.0
        
        return demand_score
    
    def _calculate_supply_score_fix(self, center_lat, center_lon, grid_size_lat, grid_size_lon):
        """ê³µê¸‰ ì ìˆ˜ ê³„ì‚° ì™„ì „ ìˆ˜ì • - 0ê°œ ë¬¸ì œ í•´ê²°"""
        if 'charging_stations' not in self.processed_data:
            return 0
        
        charging_df = self.processed_data['charging_stations']
        
        # ì„œìš¸ ì§€ì—­ ì¶©ì „ì†Œë§Œ í•„í„°ë§
        if 'ì‹œë„' in charging_df.columns:
            seoul_charging = charging_df[charging_df['ì‹œë„'].str.contains('ì„œìš¸', na=False)]
        else:
            seoul_charging = charging_df
        
        if len(seoul_charging) == 0:
            return 0
        
        # ë°©ë²• 1: ê²©ì ì¤‘ì‹¬ì ìœ¼ë¡œë¶€í„° ë°˜ê²½ 1km ë‚´ ì¶©ì „ì†Œ ì°¾ê¸°
        supply_score = 0
        
        # ì¢Œí‘œ ê¸°ë°˜ ì§ì ‘ ê³„ì‚° (ë” ì •í™•í•¨)
        if 'ê²½ë„' in seoul_charging.columns and 'ìœ„ë„' in seoul_charging.columns:
            # ì¢Œí‘œê°€ ìˆëŠ” ì¶©ì „ì†Œ ë°ì´í„° ì‚¬ìš©
            coord_charging = seoul_charging[
                seoul_charging['ê²½ë„'].notna() & seoul_charging['ìœ„ë„'].notna()
            ]
            
            if len(coord_charging) > 0:
                # ê±°ë¦¬ ê³„ì‚° (ê°„ë‹¨í•œ ìœ í´ë¦¬ë“œ ê±°ë¦¬)
                distances = np.sqrt(
                    (coord_charging['ìœ„ë„'] - center_lat) ** 2 + 
                    (coord_charging['ê²½ë„'] - center_lon) ** 2
                )
                
                # ë°˜ê²½ 0.01ë„ ë‚´ ì¶©ì „ì†Œ (ì•½ 1km)
                nearby_stations = distances < 0.01
                nearby_count = nearby_stations.sum()
                
                if nearby_count > 0:
                    # ì¶©ì „ëŸ‰ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
                    if 'ì¶©ì „ëŸ‰_numeric' in coord_charging.columns:
                        nearby_charging_amount = coord_charging[nearby_stations]['ì¶©ì „ëŸ‰_numeric'].sum()
                        supply_score += nearby_charging_amount / 100  # ìŠ¤ì¼€ì¼ ì¡°ì •
                    else:
                        supply_score += nearby_count * 10  # ì¶©ì „ì†Œ ìˆ˜ ê¸°ë°˜
        
        # ë°©ë²• 2: í–‰ì •êµ¬ì—­ ê¸°ë°˜ ê³„ì‚° (ë³´ì™„)
        if supply_score == 0:
            target_districts = self._get_districts_in_grid_fix(center_lat, center_lon)
            
            for district in target_districts:
                if 'ì‹œêµ°êµ¬' in seoul_charging.columns:
                    district_charging = seoul_charging[
                        seoul_charging['ì‹œêµ°êµ¬'].str.contains(district, na=False)
                    ]
                elif 'ì£¼ì†Œ' in seoul_charging.columns:
                    district_charging = seoul_charging[
                        seoul_charging['ì£¼ì†Œ'].str.contains(district, na=False)
                    ]
                else:
                    continue
                
                if len(district_charging) > 0:
                    if 'ì¶©ì „ëŸ‰_numeric' in district_charging.columns:
                        total_charging = district_charging['ì¶©ì „ëŸ‰_numeric'].sum()
                        supply_score += total_charging / 1000  # ìŠ¤ì¼€ì¼ ì¡°ì •
                    else:
                        supply_score += len(district_charging) * 5
        
        return max(supply_score, 0)  # ìŒìˆ˜ ë°©ì§€
    
    def _get_districts_in_grid_fix(self, center_lat, center_lon):
        """ê²©ìì— í•´ë‹¹í•˜ëŠ” ì„œìš¸ êµ¬ ì°¾ê¸° (ê°œì„ ëœ ë²„ì „)"""
        district_coords = {
            'ê°•ë‚¨êµ¬': (37.5173, 127.0473),
            'ê°•ë™êµ¬': (37.5301, 127.1238),
            'ê°•ë¶êµ¬': (37.6396, 127.0257),
            'ê°•ì„œêµ¬': (37.5509, 126.8495),
            'ê´€ì•…êµ¬': (37.4784, 126.9516),
            'ê´‘ì§„êµ¬': (37.5384, 127.0822),
            'êµ¬ë¡œêµ¬': (37.4955, 126.8578),
            'ê¸ˆì²œêµ¬': (37.4569, 126.8955),
            'ë…¸ì›êµ¬': (37.6541, 127.0568),
            'ë„ë´‰êµ¬': (37.6688, 127.0471),
            'ë™ëŒ€ë¬¸êµ¬': (37.5744, 127.0399),
            'ë™ì‘êµ¬': (37.5124, 126.9393),
            'ë§ˆí¬êµ¬': (37.5663, 126.9013),
            'ì„œëŒ€ë¬¸êµ¬': (37.5791, 126.9368),
            'ì„œì´ˆêµ¬': (37.4837, 127.0324),
            'ì„±ë™êµ¬': (37.5634, 127.0370),
            'ì„±ë¶êµ¬': (37.5894, 127.0167),
            'ì†¡íŒŒêµ¬': (37.5145, 127.1065),
            'ì–‘ì²œêµ¬': (37.5169, 126.8664),
            'ì˜ë“±í¬êµ¬': (37.5264, 126.8962),
            'ìš©ì‚°êµ¬': (37.5324, 126.9900),
            'ì€í‰êµ¬': (37.6027, 126.9291),
            'ì¢…ë¡œêµ¬': (37.5735, 126.9788),
            'ì¤‘êµ¬': (37.5641, 126.9979),
            'ì¤‘ë‘êµ¬': (37.6061, 127.0925)
        }
        
        # ê°€ì¥ ê°€ê¹Œìš´ êµ¬ë“¤ ì°¾ê¸° (ê±°ë¦¬ 0.02ë„ ì´ë‚´, ì•½ 2km)
        nearby_districts = []
        for district, (lat, lon) in district_coords.items():
            distance = ((center_lat - lat) ** 2 + (center_lon - lon) ** 2) ** 0.5
            if distance < 0.02:
                nearby_districts.append(district)
        
        # ê°€ê¹Œìš´ êµ¬ê°€ ì—†ìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ êµ¬ 1ê°œ ì„ íƒ
        if not nearby_districts:
            distances = []
            for district, (lat, lon) in district_coords.items():
                distance = ((center_lat - lat) ** 2 + (center_lon - lon) ** 2) ** 0.5
                distances.append((distance, district))
            
            closest_district = min(distances)[1]
            nearby_districts = [closest_district]
        
        return nearby_districts
    
    # ê¸°ì¡´ ë©”ì„œë“œë“¤ë„ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    def _clean_ev_registration(self, df):
        """ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._clean_ev_registration_complete_fix(df)
    
    def _clean_charging_stations(self, datasets):
        """ì¶©ì „ì†Œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._clean_charging_stations_complete_fix(datasets)
    
    def _clean_charging_hourly(self, df):
        """ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._clean_charging_hourly_complete_fix(df)
    
    def _clean_commercial_facilities(self, df):
        """ìƒì—…ì‹œì„¤ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._clean_commercial_facilities_complete_fix(df)
    
    def _create_grid_system_with_analysis(self):
        """ê²©ì ì‹œìŠ¤í…œì„ ìƒì„±í•˜ê³  ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._create_grid_system_complete_fix()
    
    def _calculate_demand_score(self, center_lat, center_lon, grid_size_lat, grid_size_lon):
        """ê²©ì ë‚´ ìˆ˜ìš” ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._calculate_demand_score_fix(center_lat, center_lon, grid_size_lat, grid_size_lon)
    
    def _calculate_supply_score(self, center_lat, center_lon, grid_size_lat, grid_size_lon):
        """ê²©ì ë‚´ ê³µê¸‰ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._calculate_supply_score_fix(center_lat, center_lon, grid_size_lat, grid_size_lon)
    
    def _get_districts_in_grid(self, center_lat, center_lon):
        """ê²©ì ì¤‘ì‹¬ì ì„ ê¸°ì¤€ìœ¼ë¡œ í•´ë‹¹í•˜ëŠ” ì„œìš¸ êµ¬ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë©”ì„œë“œ - í˜¸í™˜ì„±ìš©)"""
        return self._get_districts_in_grid_fix(center_lat, center_lon)
    
    def save_processed_data(self, output_dir='data/processed'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        import os
        
        os.makedirs(output_dir, exist_ok=True)
        
        print("ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
        
        saved_files = []
        for data_name, df in self.processed_data.items():
            filename = f"{data_name}_processed.csv"
            filepath = os.path.join(output_dir, filename)
            
            try:
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
                print(f"âœ… {filepath} ì €ì¥ ì™„ë£Œ")
                saved_files.append(filename)
            except Exception as e:
                print(f"âŒ {filepath} ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ìš”ì•½ ì •ë³´ ì €ì¥ (ì™„ì „ ìˆ˜ì •)
        summary_data = []
        for data_name, df in self.processed_data.items():
            missing_count = df.isnull().sum().sum()
            missing_rate = (missing_count / (len(df) * len(df.columns))) * 100
            
            summary_data.append({
                'dataset': data_name,
                'rows': len(df),
                'columns': len(df.columns),
                'missing_count': missing_count,
                'missing_rate': f"{missing_rate:.1f}%",
                'file_saved': f"{data_name}_processed.csv"
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_path = os.path.join(output_dir, 'preprocessing_summary.csv')
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        
        print()
        print("ğŸ“‹ ì „ì²˜ë¦¬ ìš”ì•½:")
        print(summary_df.to_string(index=False))
        print()
        print("âœ… ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼ ìˆ˜: {len(saved_files)}ê°œ")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
        
        return summary_df

# ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë“¤
def run_all_preprocessing():
    """ëª¨ë“  ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    from .data_loader import DataLoader
    
    # ë°ì´í„° ë¡œë”©
    loader = DataLoader()
    datasets = loader.load_all_datasets()
    
    if not datasets:
        print("âŒ ë¡œë”©ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    cleaner = DataCleaner()
    processed_data = cleaner.clean_all_data(datasets)
    
    # ë°ì´í„° ì €ì¥
    summary = cleaner.save_processed_data()
    
    return processed_data, summary

def create_data_cleaner():
    """DataCleaner ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    return DataCleaner()
