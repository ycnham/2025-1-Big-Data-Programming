# src/preprocessing/data_cleaner.py

import pandas as pd
import numpy as np
import re
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class DataCleaner:
    def __init__(self):
        self.processed_data = {}
    
    def clean_all_data(self, datasets):
        """ëª¨ë“  ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì „ì²˜ë¦¬
        if 'ev_registration_monthly' in datasets:
            self.processed_data['ev_registration'] = self._clean_ev_registration(
                datasets['ev_registration_monthly']
            )
        
        # ì¶©ì „ì†Œ ë°ì´í„° ì „ì²˜ë¦¬ (1-3ì›” í†µí•©)
        charging_datasets = []
        for month in ['202501', '202502', '202503']:
            key = f'charging_stations_{month}'
            if key in datasets:
                charging_datasets.append(datasets[key])
        
        if charging_datasets:
            self.processed_data['charging_stations'] = self._clean_charging_stations(charging_datasets)
        
        # ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„° ì „ì²˜ë¦¬
        if 'charging_load_hourly' in datasets:
            self.processed_data['charging_hourly'] = self._clean_charging_hourly(
                datasets['charging_load_hourly']
            )
        
        # ìƒì—…ì‹œì„¤ ë°ì´í„° ì „ì²˜ë¦¬
        if 'commercial_facilities' in datasets:
            self.processed_data['commercial_facilities'] = self._clean_commercial_facilities(
                datasets['commercial_facilities']
            )
        
        # ê²©ì ì‹œìŠ¤í…œ ìƒì„± ë° ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„
        self._create_grid_system_with_analysis()
        
        return self.processed_data
    
    def _clean_ev_registration(self, df):
        """ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
        
        # Excel íŒŒì¼ì˜ ë³µì¡í•œ í—¤ë” êµ¬ì¡° ì²˜ë¦¬
        cleaned_df = self._parse_ev_registration_excel(df)
        
        print(f"âœ… ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(cleaned_df):,}í–‰")
        return cleaned_df
    
    def _parse_ev_registration_excel(self, df):
        """ì „ê¸°ì°¨ ë“±ë¡ Excel íŒŒì¼ì˜ ë³µì¡í•œ êµ¬ì¡°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            # ì‹¤ì œ ë°ì´í„°ê°€ ì‹œì‘ë˜ëŠ” í–‰ ì°¾ê¸°
            data_start_row = None
            for i in range(min(20, len(df))):
                # 'êµ¬' ë˜ëŠ” 'ì‹œêµ°êµ¬' ê°™ì€ ì§€ì—­ ì •ë³´ê°€ ìˆëŠ” í–‰ ì°¾ê¸°
                row_values = df.iloc[i].fillna('').astype(str)
                if any('êµ¬' in str(val) and len(str(val)) > 1 for val in row_values):
                    # í—¤ë” ì°¾ê¸°
                    if i > 0:
                        header_row = i - 1
                        data_start_row = i
                        break
            
            if data_start_row is not None:
                # í—¤ë”ì™€ ë°ì´í„° ë¶„ë¦¬
                headers = df.iloc[header_row].fillna('').astype(str)
                data_df = df.iloc[data_start_row:].copy()
                
                # ì˜ë¯¸ìˆëŠ” í—¤ë”ë§Œ ì‚¬ìš©
                meaningful_headers = []
                for i, header in enumerate(headers):
                    if header and header != 'nan' and len(header.strip()) > 0:
                        meaningful_headers.append((i, header))
                    else:
                        meaningful_headers.append((i, f'col_{i}'))
                
                # ìƒˆë¡œìš´ ì»¬ëŸ¼ëª… ì„¤ì •
                new_columns = [f'col_{i}' for i in range(len(df.columns))]
                for i, header in meaningful_headers:
                    if i < len(new_columns):
                        new_columns[i] = header
                
                data_df.columns = new_columns
                
                # ë¹ˆ í–‰ ì œê±°
                data_df = data_df.dropna(how='all')
                
                # ì§€ì—­ ì •ë³´ê°€ ìˆëŠ” í–‰ë§Œ í•„í„°ë§
                region_col = None
                for col in data_df.columns:
                    if data_df[col].astype(str).str.contains('êµ¬|ì‹œ|ë™', na=False).any():
                        region_col = col
                        break
                
                if region_col:
                    data_df = data_df[data_df[region_col].astype(str).str.contains('êµ¬|ì‹œ|ë™', na=False)]
                
                return data_df.reset_index(drop=True)
            else:
                print("âš ï¸ ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ íŒŒì•…í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return df
                
        except Exception as e:
            print(f"âš ï¸ ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return df
    
    def _clean_charging_stations(self, datasets):
        """ì¶©ì „ì†Œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        # ë°ì´í„° í†µí•©
        combined_df = pd.concat(datasets, ignore_index=True)
        
        # ì¶©ì „êµ¬ë¶„ ì»¬ëŸ¼ í†µì¼
        if 'ì¶©ì „ê¸°êµ¬ë¶„' in combined_df.columns and 'ì¶©ì „êµ¬ë¶„' not in combined_df.columns:
            combined_df['ì¶©ì „êµ¬ë¶„'] = combined_df['ì¶©ì „ê¸°êµ¬ë¶„']
        elif 'ì¶©ì „ê¸°êµ¬ë¶„' in combined_df.columns and 'ì¶©ì „êµ¬ë¶„' in combined_df.columns:
            combined_df['ì¶©ì „êµ¬ë¶„'] = combined_df['ì¶©ì „êµ¬ë¶„'].fillna(combined_df['ì¶©ì „ê¸°êµ¬ë¶„'])
        
        print(f"ğŸ“Š í†µí•©ëœ ë°ì´í„° í˜•íƒœ: {combined_df.shape}")
        
        # ì¶©ì „ëŸ‰ ë°ì´í„° ì •ë¦¬
        if 'ì¶©ì „ëŸ‰' in combined_df.columns:
            # ì¶©ì „ëŸ‰ì„ ìˆ«ìë¡œ ë³€í™˜
            combined_df['ì¶©ì „ëŸ‰_numeric'] = pd.to_numeric(combined_df['ì¶©ì „ëŸ‰'], errors='coerce')
            
            # ì´ìƒì¹˜ ì œê±°
            before_count = len(combined_df)
            combined_df = combined_df[
                (combined_df['ì¶©ì „ëŸ‰_numeric'] >= 0) & 
                (combined_df['ì¶©ì „ëŸ‰_numeric'] <= 1000)
            ].copy()
            after_count = len(combined_df)
            
            print(f"ğŸ“Š ì¶©ì „ëŸ‰ ì´ìƒì¹˜ ì œê±°: {before_count:,}í–‰ â†’ {after_count:,}í–‰")
        
        # ë‚ ì§œ ë°ì´í„° ì •ë¦¬
        date_columns = ['ì¶©ì „ì¢…ë£Œì¼', 'ì¶©ì „ì‹œì‘ì‹œê°', 'ì¶©ì „ì¢…ë£Œì‹œê°']
        for col in date_columns:
            if col in combined_df.columns:
                combined_df[col] = pd.to_datetime(combined_df[col], errors='coerce')
        
        print(f"âœ… ì¶©ì „ì†Œ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(combined_df):,}í–‰")
        return combined_df
    
    def _clean_charging_hourly(self, df):
        """ì„œìš¸ì‹œ ì¶©ì „ê¸° ì‹œê°„ë³„ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ì„œìš¸ì‹œ ì¶©ì „ê¸° ì‹œê°„ë³„ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
        
        # í—¤ë”ê°€ ìˆëŠ” í–‰ ì°¾ê¸°
        header_row = None
        for i in range(min(10, len(df))):
            if 'ìˆœë²ˆ' in str(df.iloc[i, 0]):
                header_row = i
                break
        
        if header_row is not None:
            # ìƒˆë¡œìš´ ì»¬ëŸ¼ëª… ì„¤ì •
            new_columns = df.iloc[header_row].fillna('Unknown').astype(str)
            # ì‹¤ì œ ë°ì´í„°ë§Œ ì¶”ì¶œ
            cleaned_df = df.iloc[header_row+1:].copy()
            cleaned_df.columns = new_columns
            
            # ë¹ˆ í–‰ ë° ë¹„ì •ìƒ ë°ì´í„° ì œê±°
            cleaned_df = cleaned_df.dropna(how='all')
            
            # ìˆœë²ˆì´ ìˆ«ìì¸ í–‰ë§Œ ìœ ì§€
            if 'ìˆœë²ˆ' in cleaned_df.columns:
                cleaned_df = cleaned_df[pd.to_numeric(cleaned_df['ìˆœë²ˆ'], errors='coerce').notna()]
        else:
            cleaned_df = df.copy()
        
        print(f"âœ… ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(cleaned_df)}í–‰")
        return cleaned_df
    
    def _clean_commercial_facilities(self, df):
        """ìƒì—…ì‹œì„¤ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ìƒì—…ì‹œì„¤ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
        
        # ì¢Œí‘œ ë°ì´í„° í•„í„°ë§ (ì„œìš¸ ì§€ì—­)
        before_count = len(df)
        if 'ê²½ë„' in df.columns and 'ìœ„ë„' in df.columns:
            df_filtered = df[
                (df['ê²½ë„'].between(126.7, 127.2)) & 
                (df['ìœ„ë„'].between(37.4, 37.7))
            ].copy()
        else:
            df_filtered = df.copy()
        
        after_count = len(df_filtered)
        print(f"ğŸ“ ìƒì—…ì‹œì„¤ ì¢Œí‘œ í•„í„°ë§: {before_count:,}í–‰ â†’ {after_count:,}í–‰")
        
        # ì—…ì¢… ë¶„ë¥˜ ì •ë¦¬
        if 'ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…' in df_filtered.columns:
            df_filtered['ì—…ì¢…_ëŒ€ë¶„ë¥˜'] = df_filtered['ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…']
        
        if 'ìƒê¶Œì—…ì¢…ì¤‘ë¶„ë¥˜ëª…' in df_filtered.columns:
            df_filtered['ì—…ì¢…_ì¤‘ë¶„ë¥˜'] = df_filtered['ìƒê¶Œì—…ì¢…ì¤‘ë¶„ë¥˜ëª…']
        
        print("ğŸª ì—…ì¢… ë¶„ë¥˜ ì •ë¦¬ ì™„ë£Œ")
        print(f"âœ… ìƒì—…ì‹œì„¤ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df_filtered):,}í–‰")
        return df_filtered
    
    def _create_grid_system_with_analysis(self):
        """500m x 500m ê²©ì ì‹œìŠ¤í…œì„ ìƒì„±í•˜ê³  ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        print("ğŸ—ºï¸ 500m x 500m ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì¤‘...")
        
        # ì„œìš¸ ì§€ì—­ ê²½ê³„
        seoul_bounds = {
            'min_lat': 37.4,
            'max_lat': 37.7,
            'min_lon': 126.7,
            'max_lon': 127.2
        }
        
        # 500më¥¼ ìœ„ë„/ê²½ë„ë¡œ ë³€í™˜
        grid_size_lat = 0.5 / 111  # 500më¥¼ ìœ„ë„ë¡œ ë³€í™˜
        grid_size_lon = 0.5 / 88.8  # 500më¥¼ ê²½ë„ë¡œ ë³€í™˜
        
        # ê²©ì ìƒì„±
        lats = np.arange(seoul_bounds['min_lat'], seoul_bounds['max_lat'], grid_size_lat)
        lons = np.arange(seoul_bounds['min_lon'], seoul_bounds['max_lon'], grid_size_lon)
        
        grid_data = []
        
        for i, lat in enumerate(lats):
            for j, lon in enumerate(lons):
                grid_center_lat = lat + grid_size_lat/2
                grid_center_lon = lon + grid_size_lon/2
                
                # ìˆ˜ìš” ê³„ì‚° (ìƒì—…ì‹œì„¤ ë°€ë„ ê¸°ë°˜)
                demand_score = self._calculate_demand_score(
                    grid_center_lat, grid_center_lon, grid_size_lat, grid_size_lon
                )
                
                # ê³µê¸‰ ê³„ì‚° (ì¶©ì „ì†Œ ìˆ˜ ê¸°ë°˜)
                supply_score = self._calculate_supply_score(
                    grid_center_lat, grid_center_lon, grid_size_lat, grid_size_lon
                )
                
                grid_data.append({
                    'grid_id': f'GRID_{i}_{j}',
                    'min_lat': lat,
                    'max_lat': lat + grid_size_lat,
                    'min_lon': lon,
                    'max_lon': lon + grid_size_lon,
                    'center_lat': grid_center_lat,
                    'center_lon': grid_center_lon,
                    'demand_score': demand_score,
                    'supply_score': supply_score
                })
        
        grid_df = pd.DataFrame(grid_data)
        self.processed_data['grid_system'] = grid_df
        
        print(f"âœ… ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ: {len(grid_df):,}ê°œ ê²©ì")
        print(f"ğŸ“Š ìˆ˜ìš”ê°€ ìˆëŠ” ê²©ì: {(grid_df['demand_score'] > 0).sum():,}ê°œ")
        print(f"ğŸ“Š ê³µê¸‰ì´ ìˆëŠ” ê²©ì: {(grid_df['supply_score'] > 0).sum():,}ê°œ")
        
        return grid_df
    
    def _calculate_demand_score(self, center_lat, center_lon, grid_size_lat, grid_size_lon):
        """ê²©ì ë‚´ ìˆ˜ìš” ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if 'commercial_facilities' not in self.processed_data:
            return 0
        
        facilities_df = self.processed_data['commercial_facilities']
        
        # ê²©ì ë²”ìœ„ ë‚´ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚°
        min_lat = center_lat - grid_size_lat/2
        max_lat = center_lat + grid_size_lat/2
        min_lon = center_lon - grid_size_lon/2
        max_lon = center_lon + grid_size_lon/2
        
        if 'ê²½ë„' in facilities_df.columns and 'ìœ„ë„' in facilities_df.columns:
            facilities_in_grid = facilities_df[
                (facilities_df['ìœ„ë„'].between(min_lat, max_lat)) &
                (facilities_df['ê²½ë„'].between(min_lon, max_lon))
            ]
            
            # ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            demand_score = 0
            if len(facilities_in_grid) > 0:
                if 'ì—…ì¢…_ëŒ€ë¶„ë¥˜' in facilities_in_grid.columns or 'ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…' in facilities_in_grid.columns:
                    # ì—…ì¢… ì»¬ëŸ¼ ì°¾ê¸°
                    business_col = 'ì—…ì¢…_ëŒ€ë¶„ë¥˜' if 'ì—…ì¢…_ëŒ€ë¶„ë¥˜' in facilities_in_grid.columns else 'ìƒê¶Œì—…ì¢…ëŒ€ë¶„ë¥˜ëª…'
                    
                    # ìŒì‹ì , ì†Œë§¤ì—… ë“±ì— ë†’ì€ ê°€ì¤‘ì¹˜
                    weights = {'ìŒì‹': 3, 'ì†Œë§¤': 2, 'ì„œë¹„ìŠ¤': 1, 'êµìœ¡': 1, 'ê³¼í•™': 1}
                    
                    for category, weight in weights.items():
                        count = facilities_in_grid[business_col].str.contains(category, na=False).sum()
                        demand_score += count * weight
                    
                    # ê°€ì¤‘ì¹˜ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì‹œì„¤ë“¤ë„ ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬
                    unweighted_count = len(facilities_in_grid)
                    for category in weights.keys():
                        unweighted_count -= facilities_in_grid[business_col].str.contains(category, na=False).sum()
                    demand_score += max(0, unweighted_count) * 0.5
                else:
                    demand_score = len(facilities_in_grid)
            
            return demand_score
        
        return 0
    
    def _calculate_supply_score(self, center_lat, center_lon, grid_size_lat, grid_size_lon):
        """ê²©ì ë‚´ ê³µê¸‰ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if 'charging_stations' not in self.processed_data:
            return 0
        
        charging_df = self.processed_data['charging_stations']
        
        # ì„œìš¸ ì§€ì—­ ì¶©ì „ì†Œë§Œ í•„í„°ë§
        seoul_charging = charging_df[charging_df['ì‹œë„'].str.contains('ì„œìš¸', na=False)]
        
        if len(seoul_charging) == 0:
            return 0
        
        # ê²©ì ë²”ìœ„ ë‚´ ì¶©ì „ì†Œ ì°¾ê¸° (ì£¼ì†Œ ê¸°ë°˜)
        grid_districts = self._get_districts_in_grid(center_lat, center_lon)
        
        supply_score = 0
        
        # ê° êµ¬ë³„ë¡œ ì¶©ì „ ê¸°ë¡ ìˆ˜ ê³„ì‚°
        for district in grid_districts:
            # ì£¼ì†Œì— í•´ë‹¹ êµ¬ê°€ í¬í•¨ëœ ì¶©ì „ ê¸°ë¡ ì°¾ê¸°
            district_charging = seoul_charging[seoul_charging['ì£¼ì†Œ'].str.contains(district, na=False)]
            
            if len(district_charging) > 0:
                # ì¶©ì „ëŸ‰ì„ ê³ ë ¤í•œ ê³µê¸‰ ì ìˆ˜ ê³„ì‚°
                if 'ì¶©ì „ëŸ‰_numeric' in district_charging.columns:
                    total_charging = district_charging['ì¶©ì „ëŸ‰_numeric'].sum()
                    supply_score += total_charging
                else:
                    supply_score += len(district_charging)
        
        # ê²©ì í¬ê¸°ì— ë”°ë¥¸ ì¡°ì • (ë” ì‘ì€ ê²©ìì¼ìˆ˜ë¡ ì ìˆ˜ë¥¼ ì„¸ë¶„í™”)
        grid_area = grid_size_lat * grid_size_lon
        adjustment_factor = grid_area / (0.5/111 * 0.5/88.8)  # ê¸°ì¤€ ê²©ì í¬ê¸° ëŒ€ë¹„
        
        return supply_score * adjustment_factor
    
    def _get_districts_in_grid(self, center_lat, center_lon):
        """ê²©ì ì¤‘ì‹¬ì ì„ ê¸°ì¤€ìœ¼ë¡œ í•´ë‹¹í•˜ëŠ” ì„œìš¸ êµ¬ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."""
        # ëŒ€ëµì ì¸ ì„œìš¸ êµ¬ë³„ ì¢Œí‘œ (ì¤‘ì‹¬ì  ê¸°ì¤€)
        district_coords = {
            'ê°•ë‚¨êµ¬': (37.517, 127.047),
            'ê°•ë™êµ¬': (37.530, 127.124),
            'ê°•ë¶êµ¬': (37.639, 127.025),
            'ê°•ì„œêµ¬': (37.551, 126.850),
            'ê´€ì•…êµ¬': (37.478, 126.951),
            'ê´‘ì§„êµ¬': (37.538, 127.082),
            'êµ¬ë¡œêµ¬': (37.495, 126.858),
            'ê¸ˆì²œêµ¬': (37.457, 126.895),
            'ë…¸ì›êµ¬': (37.654, 127.056),
            'ë„ë´‰êµ¬': (37.669, 127.047),
            'ë™ëŒ€ë¬¸êµ¬': (37.574, 127.040),
            'ë™ì‘êµ¬': (37.512, 126.940),
            'ë§ˆí¬êµ¬': (37.566, 126.901),
            'ì„œëŒ€ë¬¸êµ¬': (37.579, 126.937),
            'ì„œì´ˆêµ¬': (37.484, 127.033),
            'ì„±ë™êµ¬': (37.563, 127.037),
            'ì„±ë¶êµ¬': (37.589, 127.017),
            'ì†¡íŒŒêµ¬': (37.515, 127.106),
            'ì–‘ì²œêµ¬': (37.517, 126.867),
            'ì˜ë“±í¬êµ¬': (37.526, 126.896),
            'ìš©ì‚°êµ¬': (37.532, 126.990),
            'ì€í‰êµ¬': (37.603, 126.929),
            'ì¢…ë¡œêµ¬': (37.573, 126.979),
            'ì¤‘êµ¬': (37.564, 126.997),
            'ì¤‘ë‘êµ¬': (37.606, 127.093)
        }
        
        # ê°€ì¥ ê°€ê¹Œìš´ êµ¬ ì°¾ê¸° (ê±°ë¦¬ 0.02ë„ ì´ë‚´, ì•½ 2km)
        nearby_districts = []
        for district, (lat, lon) in district_coords.items():
            distance = ((center_lat - lat) ** 2 + (center_lon - lon) ** 2) ** 0.5
            if distance < 0.02:  # ì•½ 2km ë°˜ê²½
                nearby_districts.append(district)
        
        return nearby_districts if nearby_districts else ['ì„œìš¸']
    
    def save_processed_data(self, output_dir='data/processed'):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        import os
        
        os.makedirs(output_dir, exist_ok=True)
        
        print("ğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘...")
        
        saved_files = []
        for data_name, df in self.processed_data.items():
            filename = f"{data_name}_processed.csv"
            filepath = os.path.join(output_dir, filename)
            
            try:
                df.to_csv(filepath, index=False, encoding='utf-8-sig')
                print(f"âœ… {filepath} ì €ì¥ ì™„ë£Œ")
                saved_files.append(filename)
            except Exception as e:
                print(f"âŒ {filepath} ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ìš”ì•½ ì •ë³´ ì €ì¥
        summary_data = []
        for data_name, df in self.processed_data.items():
            summary_data.append({
                'dataset': data_name,
                'rows': len(df),
                'columns': len(df.columns),
                'file_saved': f"{data_name}_processed.csv"
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_path = os.path.join(output_dir, 'preprocessing_summary.csv')
        summary_df.to_csv(summary_path, index=False, encoding='utf-8-sig')
        
        print()
        print("ğŸ“‹ ì „ì²˜ë¦¬ ìš”ì•½:")
        print(summary_df.to_string(index=False))
        print()
        print("âœ… ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼ ìˆ˜: {len(saved_files)}ê°œ")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}/")
        
        return summary_df

# ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë“¤
def run_all_preprocessing():
    """ëª¨ë“  ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    from .data_loader import DataLoader
    
    # ë°ì´í„° ë¡œë”©
    loader = DataLoader()
    datasets = loader.load_all_datasets()
    
    if not datasets:
        print("âŒ ë¡œë”©ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    cleaner = DataCleaner()
    processed_data = cleaner.clean_all_data(datasets)
    
    # ë°ì´í„° ì €ì¥
    summary = cleaner.save_processed_data()
    
    return processed_data, summary

def create_data_cleaner():
    """DataCleaner ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    return DataCleaner()