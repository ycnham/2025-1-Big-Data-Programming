# src/preprocessing/modeling_data_prep.py
# ëª¨ë¸ë§ì„ ìœ„í•œ ì™„ì „ ìˆ˜ì •ëœ ì „ì²˜ë¦¬ ì½”ë“œ (ycnham + mg ë¸Œëœì¹˜ í†µí•©)

import pandas as pd
import numpy as np
from pathlib import Path
import os
import sys
from collections import defaultdict

# ì•ˆì „í•œ import ì²˜ë¦¬
try:
    import warnings
    warnings.filterwarnings('ignore')
except ImportError:
    pass

class ImprovedDemandScoreCalculator:
    """ê°œì„ ëœ ìˆ˜ìš” ì ìˆ˜ ê³„ì‚°ê¸° (ycnham ë¸Œëœì¹˜ ê¸°ëŠ¥)"""
    
    def __init__(self, processed_data_dir):
        self.processed_dir = Path(processed_data_dir)
        
        # ì—…ì¢…ë³„ ì „ê¸°ì°¨ ìˆ˜ìš” ê°€ì¤‘ì¹˜ ì •ì˜
        self.business_weights = {
            # ë†’ì€ ìˆ˜ìš” ì—…ì¢… (ê°€ì¤‘ì¹˜ 3.0)
            'ìŒì‹': 3.0,  # ë ˆìŠ¤í† ë‘, ì¹´í˜ ë“± ì²´ë¥˜ì‹œê°„ ì ë‹¹
            'ì†Œë§¤': 2.5,  # ì‡¼í•‘ëª°, ë§ˆíŠ¸ ë“± ì¤‘ê°„ ì²´ë¥˜ì‹œê°„
            'ê³¼í•™Â·ê¸°ìˆ ': 2.0,  # ì—…ë¬´ì‹œì„¤
            
            # ì¤‘ê°„ ìˆ˜ìš” ì—…ì¢… (ê°€ì¤‘ì¹˜ 1.5)
            'ë¶€ë™ì‚°': 1.5,
            'ì‹œì„¤ê´€ë¦¬Â·ì„ëŒ€': 1.5,
            'ìˆ˜ë¦¬Â·ê°œì¸': 1.5,
            
            # ë‚®ì€ ìˆ˜ìš” ì—…ì¢… (ê°€ì¤‘ì¹˜ 1.0)
            'ì˜ˆìˆ Â·ìŠ¤í¬ì¸ ': 1.0,
            'ê¸°íƒ€': 1.0
        }
        
        # ì‹œê°„ëŒ€ë³„ ì¶©ì „ íŒ¨í„´ ê°€ì¤‘ì¹˜ (24ì‹œê°„)
        self.hourly_weights = np.array([
            0.3, 0.2, 0.2, 0.2, 0.3, 0.5,  # 0-5ì‹œ: ì•¼ê°„
            0.8, 1.2, 1.5, 1.3, 1.2, 1.4,  # 6-11ì‹œ: ì˜¤ì „ ì¶œê·¼/ì—…ë¬´
            1.6, 1.4, 1.3, 1.5, 1.7, 1.8,  # 12-17ì‹œ: ì ì‹¬/ì˜¤í›„
            1.9, 2.0, 1.8, 1.5, 1.0, 0.6   # 18-23ì‹œ: ì €ë…/í‡´ê·¼
        ])
    
    def load_data(self):
        """ëª¨ë“  í•„ìš”í•œ ë°ì´í„° ë¡œë”©"""
        try:
            # 1. ì‹œê°„ë³„ ì¶©ì „ ë°ì´í„°
            charging_file = self.processed_dir / 'charging_hourly_processed.csv'
            if charging_file.exists():
                self.charging_df = pd.read_csv(charging_file)
                print(f"   âœ… ì¶©ì „ ë°ì´í„° ë¡œë”©: {len(self.charging_df):,}í–‰")
            else:
                self.charging_df = pd.DataFrame()
                print("   âš ï¸ ì¶©ì „ ë°ì´í„° ì—†ìŒ")
            
            # 2. ìƒì—…ì‹œì„¤ ë°ì´í„°
            commercial_file = self.processed_dir / 'commercial_facilities_processed.csv'
            if commercial_file.exists():
                # íŒŒì¼ í¬ê¸° ì²´í¬
                file_size_mb = commercial_file.stat().st_size / (1024 * 1024)
                if file_size_mb > 200:  # 200MB ì´ìƒì´ë©´ ì²­í¬ë¡œ ë¡œë”©
                    print(f"   ğŸ“Š ëŒ€ìš©ëŸ‰ ìƒì—…ì‹œì„¤ ë°ì´í„° ì²­í¬ ë¡œë”© (í¬ê¸°: {file_size_mb:.1f}MB)")
                    self.commercial_df = pd.read_csv(commercial_file, nrows=100000)  # ìƒ˜í”Œë§
                else:
                    self.commercial_df = pd.read_csv(commercial_file)
                print(f"   âœ… ìƒì—…ì‹œì„¤ ë°ì´í„° ë¡œë”©: {len(self.commercial_df):,}í–‰")
            else:
                self.commercial_df = pd.DataFrame()
                print("   âš ï¸ ìƒì—…ì‹œì„¤ ë°ì´í„° ì—†ìŒ")
            
            # 3. ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„°
            ev_file = self.processed_dir / 'ev_registration_processed.csv'
            if ev_file.exists():
                self.ev_df = pd.read_csv(ev_file)
                print(f"   âœ… ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ë¡œë”©: {len(self.ev_df):,}í–‰")
            else:
                self.ev_df = pd.DataFrame()
                print("   âš ï¸ ì „ê¸°ì°¨ ë“±ë¡ ë°ì´í„° ì—†ìŒ")
                
            return True
            
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return False
    
    def calculate_actual_charging_demand(self, lat, lon, radius=0.01):
        """ì‹¤ì œ ì¶©ì „ëŸ‰ ê¸°ë°˜ ìˆ˜ìš” ê³„ì‚°"""
        if self.charging_df.empty:
            return 0.0
        
        try:
            # ì„œìš¸ ì§€ì—­ ë°ì´í„°ë§Œ í•„í„°ë§
            if 'ì¶©ì „ì†Œëª…' in self.charging_df.columns:
                seoul_charging = self.charging_df[
                    self.charging_df['ì¶©ì „ì†Œëª…'].str.contains('ì„œìš¸|ê°•ë‚¨|ê°•ë¶|ì†¡íŒŒ|ì„œì´ˆ|ì¢…ë¡œ|ì¤‘êµ¬|ì„±ë™|ë§ˆí¬', na=False)
                ]
            else:
                seoul_charging = self.charging_df
            
            if len(seoul_charging) == 0:
                return 0.0
            
            # ì¶©ì „ëŸ‰ ê¸°ë°˜ ìˆ˜ìš” ê³„ì‚°
            if 'ì¶©ì „ëŸ‰(kW)' in seoul_charging.columns:
                total_demand = seoul_charging['ì¶©ì „ëŸ‰(kW)'].sum()
                # ì •ê·œí™” (ì „ì²´ ì¶©ì „ëŸ‰ì„ ê²©ìë³„ë¡œ ë¶„ë°°)
                grid_demand = total_demand / max(len(seoul_charging), 1000)
                return min(grid_demand * 2, 50)  # 0-50 ë²”ìœ„ë¡œ ì •ê·œí™”
            
            return 0.0
            
        except Exception:
            return 0.0
    
    def calculate_commercial_demand(self, lat, lon, radius=0.005):
        """ìƒì—…ì‹œì„¤ ê¸°ë°˜ ìˆ˜ìš” ê³„ì‚° (ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜ ì ìš©)"""
        if self.commercial_df.empty:
            return 0.0, 0
        
        try:
            # ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš° ë°˜ê²½ ë‚´ ì‹œì„¤ ì°¾ê¸°
            if 'ê²½ë„' in self.commercial_df.columns and 'ìœ„ë„' in self.commercial_df.columns:
                lat_diff = abs(self.commercial_df['ìœ„ë„'] - lat)
                lon_diff = abs(self.commercial_df['ê²½ë„'] - lon)
                nearby_mask = (lat_diff <= radius) & (lon_diff <= radius)
                nearby_facilities = self.commercial_df[nearby_mask]
            else:
                # ì¢Œí‘œê°€ ì—†ìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§ìœ¼ë¡œ ì¶”ì •
                sample_size = min(50, len(self.commercial_df))
                nearby_facilities = self.commercial_df.sample(sample_size)
            
            if len(nearby_facilities) == 0:
                return 0.0, 0
            
            # ì—…ì¢…ë³„ ê°€ì¤‘ ìˆ˜ìš” ê³„ì‚°
            weighted_demand = 0.0
            facility_count = len(nearby_facilities)
            
            if 'ì—…ì¢…_ëŒ€ë¶„ë¥˜' in nearby_facilities.columns:
                for _, facility in nearby_facilities.iterrows():
                    business_type = facility.get('ì—…ì¢…_ëŒ€ë¶„ë¥˜', 'ê¸°íƒ€')
                    weight = self.business_weights.get(business_type, 1.0)
                    weighted_demand += weight
            else:
                # ì—…ì¢… ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì ìš©
                weighted_demand = facility_count * 1.5
            
            # ì •ê·œí™” (0-50 ë²”ìœ„)
            normalized_demand = min(weighted_demand, 50)
            
            return normalized_demand, facility_count
            
        except Exception:
            return 0.0, 0
    
    def calculate_ev_registration_factor(self, lat, lon):
        """ì „ê¸°ì°¨ ë“±ë¡ í˜„í™© ê¸°ë°˜ ë³´ì • ê³„ìˆ˜"""
        if self.ev_df.empty:
            return 1.0
        
        try:
            # ì„œìš¸ ì§€ì—­ í‰ê·  ì „ê¸°ì°¨ ìˆ˜ ê³„ì‚°
            seoul_ev_avg = self.ev_df['ì „ê¸°ì°¨_ìˆ˜'].mean()
            
            # ìœ„ì¹˜ ê¸°ë°˜ ë³´ì • (ì¢Œí‘œ-í–‰ì •êµ¬ì—­ ë§¤í•‘ ê°„ì†Œí™”)
            if seoul_ev_avg > 400:
                return 1.3  # ë†’ì€ ì „ê¸°ì°¨ ë³´ê¸‰ë¥  (ì†¡íŒŒ, ì„œì´ˆ ë“±)
            elif seoul_ev_avg > 250:
                return 1.1  # ì¤‘ê°„ ì „ê¸°ì°¨ ë³´ê¸‰ë¥ 
            else:
                return 1.0  # ê¸°ë³¸ ë³´ì •
                
        except Exception:
            return 1.0
    
    def calculate_time_pattern_factor(self):
        """ì‹œê°„ëŒ€ë³„ ì¶©ì „ íŒ¨í„´ ë³´ì • ê³„ìˆ˜"""
        if self.charging_df.empty:
            return 1.0
        
        try:
            # ì¶©ì „ ì‹œì‘ ì‹œê°„ ë¶„ì„
            if 'ì¶©ì „ì‹œì‘ì‹œê°' in self.charging_df.columns:
                charging_hours = pd.to_datetime(
                    self.charging_df['ì¶©ì „ì‹œì‘ì‹œê°'], errors='coerce'
                ).dt.hour
                
                # í”¼í¬ ì‹œê°„ëŒ€ (ì˜¤í›„ 6-8ì‹œ) ì¶©ì „ëŸ‰ì´ ë§ìœ¼ë©´ ë†’ì€ ìˆ˜ìš”ë¡œ íŒë‹¨
                peak_ratio = (charging_hours.between(18, 20)).mean()
                return 1.0 + peak_ratio * 0.5  # 1.0-1.5 ë²”ìœ„
            
            return 1.1  # ê¸°ë³¸ ì‹œê°„ ë³´ì •
            
        except Exception:
            return 1.1
    
    def calculate_accessibility_score(self, lat, lon):
        """ì ‘ê·¼ì„± ì ìˆ˜ ê³„ì‚°"""
        # ì„œìš¸ ì£¼ìš” êµí†µ í—ˆë¸Œ
        major_hubs = [
            (37.5665, 126.9780),  # ì‹œì²­/ì¤‘êµ¬
            (37.5173, 127.0473),  # ê°•ë‚¨ì—­
            (37.5407, 127.0700),  # í™ëŒ€
            (37.4837, 127.0324),  # ì„œì´ˆ
            (37.5145, 127.1065),  # ì ì‹¤
            (37.5799, 126.9770),  # ì¢…ë¡œ
            (37.5443, 127.0557),  # ì„±ë™êµ¬
        ]
        
        min_distance = float('inf')
        for hub_lat, hub_lon in major_hubs:
            distance = np.sqrt((lat - hub_lat)**2 + (lon - hub_lon)**2)
            min_distance = min(min_distance, distance)
        
        # ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ì ‘ê·¼ì„± ì ìˆ˜ (0-100)
        accessibility = max(0, 100 - min_distance * 1500)
        return accessibility

class ModelingDataPreprocessor:
    def __init__(self, processed_data_dir='data/processed', output_dir='data/processed'):
        """ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì´ˆê¸°í™” (ycnham + mg í†µí•©)"""
        self.project_root = self._find_project_root()
        
        # ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
        if isinstance(processed_data_dir, str):
            self.processed_dir = self.project_root / processed_data_dir
        else:
            self.processed_dir = Path(processed_data_dir)
            
        if isinstance(output_dir, str):
            self.output_dir = self.project_root / output_dir
        else:
            self.output_dir = Path(output_dir)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”§ í†µí•© ëª¨ë¸ë§ ì „ì²˜ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {self.processed_dir}")
        print(f"   ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
    
    def _find_project_root(self):
        """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
        current = Path.cwd()
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ë¶€í„° ìƒìœ„ë¡œ ì˜¬ë¼ê°€ë©° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
        while current.parent != current:
            if (current / 'src').exists() and (current / 'data').exists():
                return current
            current = current.parent
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ ë°˜í™˜
        return Path.cwd()
    
    def prepare_all_modeling_data(self):
        """ëª¨ë¸ë§ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. (ycnham + mg í†µí•©)"""
        print("ğŸš€ í†µí•© ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        success_count = 0
        total_steps = 6  # ê°œì„ ëœ ë°©ë²• + ê¸°ì¡´ ë°©ë²• ëª¨ë‘ ì§€ì›
        
        try:
            # 1. grid_system_processed.csv í™•ì¸ ë° ìƒì„±
            print("\n1ï¸âƒ£ ê²©ì ì‹œìŠ¤í…œ ë°ì´í„° ì¤€ë¹„...")
            if self._prepare_grid_system():
                success_count += 1
                print("   âœ… ê²©ì ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
            else:
                print("   âš ï¸ ê²©ì ì‹œìŠ¤í…œ ì¤€ë¹„ ë¶€ë¶„ ì„±ê³µ")
            
            # 2. grid_features.csv ìƒì„± (ê°œì„ ëœ ë²„ì „ ìš°ì„  ì‹œë„)
            print("\n2ï¸âƒ£ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± (ê°œì„ ëœ ìˆ˜ìš” ì ìˆ˜ í¬í•¨)...")
            if self._prepare_grid_features_improved():
                success_count += 1
                print("   âœ… ê°œì„ ëœ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ì™„ë£Œ")
            else:
                print("   âš ï¸ ê°œì„ ëœ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ë¶€ë¶„ ì„±ê³µ")
            
            # 3. ê¸°ì¡´ ë°©ì‹ì˜ grid_features.csvë„ ë°±ì—…ìœ¼ë¡œ ìƒì„±
            print("\n3ï¸âƒ£ ê¸°ì¡´ ë°©ì‹ ê²©ì íŠ¹ì„± ë°ì´í„° ë°±ì—… ìƒì„±...")
            if self._prepare_grid_features_original():
                success_count += 1
                print("   âœ… ê¸°ì¡´ ë°©ì‹ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ì™„ë£Œ")
            else:
                print("   âš ï¸ ê¸°ì¡´ ë°©ì‹ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ë¶€ë¶„ ì„±ê³µ")
            
            # 4. demand_supply_analysis.csv ìƒì„±
            print("\n4ï¸âƒ£ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ë°ì´í„° ìƒì„±...")
            if self._prepare_demand_supply_analysis():
                success_count += 1
                print("   âœ… ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ì™„ë£Œ")
            else:
                print("   âš ï¸ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ë¶€ë¶„ ì„±ê³µ")
            
            # 5. optimal_locations.csv ìƒì„±
            print("\n5ï¸âƒ£ ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„±...")
            if self._prepare_optimal_locations():
                success_count += 1
                print("   âœ… ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„± ì™„ë£Œ")
            else:
                print("   âš ï¸ ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„± ë¶€ë¶„ ì„±ê³µ")
            
            # 6. ë°ì´í„° ê²€ì¦
            print("\n6ï¸âƒ£ ìƒì„±ëœ ë°ì´í„° ê²€ì¦...")
            if self._validate_generated_data():
                success_count += 1
                print("   âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
            else:
                print("   âš ï¸ ë°ì´í„° ê²€ì¦ ë¶€ë¶„ ì„±ê³µ")
            
            # ê²°ê³¼ ìš”ì•½
            success_rate = success_count / total_steps * 100
            print(f"\nğŸ“Š í†µí•© ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ì„±ê³µë¥ : {success_count}/{total_steps} ({success_rate:.1f}%)")
            
            if success_count >= 5:
                print("âœ… ëª¨ë¸ë§ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                return True
            elif success_count >= 3:
                print("âš ï¸ ê¸°ë³¸ì ì¸ ëª¨ë¸ë§ ë°ì´í„°ëŠ” ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return True
            else:
                print("âŒ ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
                return False
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _prepare_grid_system(self):
        """grid_system_processed.csv í™•ì¸ ë° ë³´ì • (ycnham ê³ ê¸‰ ë²„ì „)"""
        try:
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            
            if grid_file.exists():
                df = pd.read_csv(grid_file)
                print(f"   ğŸ“Š ê¸°ì¡´ ê²©ì íŒŒì¼ ë°œê²¬: {len(df):,}í–‰")
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì¶”ê°€
                required_cols = ['grid_id', 'center_lat', 'center_lon', 'demand_score', 'supply_score']
                missing_cols = [col for col in required_cols if col not in df.columns]
                
                if missing_cols:
                    print(f"   ğŸ”§ ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€: {missing_cols}")
                    
                    for col in missing_cols:
                        if col == 'grid_id':
                            # ê¸°ì¡´ ì»¬ëŸ¼ í™œìš©í•˜ì—¬ grid_id ìƒì„±
                            if 'grid_x' in df.columns and 'grid_y' in df.columns:
                                df['grid_id'] = df.apply(lambda row: f"GRID_{int(row['grid_x']):03d}_{int(row['grid_y']):03d}", axis=1)
                            else:
                                df['grid_id'] = [f'GRID_{i:05d}' for i in range(len(df))]
                        elif col == 'demand_score':
                            # ê¸°ì¡´ ìˆ˜ìš” ê´€ë ¨ ì»¬ëŸ¼ ë§¤í•‘
                            if 'total_demand' in df.columns:
                                df[col] = df['total_demand']
                            elif 'demand' in df.columns:
                                df[col] = df['demand']
                            else:
                                # ìœ„ì¹˜ ê¸°ë°˜ ì„ì‹œ ë°ì´í„° (ì¤‘ì‹¬ë¶€ ë†’ê²Œ) - ycnham ë°©ì‹
                                seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
                                distances = np.sqrt((df['center_lat'] - seoul_center_lat)**2 + (df['center_lon'] - seoul_center_lon)**2)
                                weights = np.maximum(0.1, 1 - distances * 8)
                                df[col] = np.maximum(0, np.random.normal(30 * weights, 15))
                        elif col == 'supply_score':
                            # ê¸°ì¡´ ê³µê¸‰ ê´€ë ¨ ì»¬ëŸ¼ ë§¤í•‘
                            if 'total_supply' in df.columns:
                                df[col] = df['total_supply']
                            elif 'supply' in df.columns:
                                df[col] = df['supply']
                            else:
                                # ìœ„ì¹˜ ê¸°ë°˜ ì„ì‹œ ë°ì´í„° - ycnham ë°©ì‹
                                seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
                                distances = np.sqrt((df['center_lat'] - seoul_center_lat)**2 + (df['center_lon'] - seoul_center_lon)**2)
                                weights = np.maximum(0.2, 1 - distances * 5)
                                df[col] = np.maximum(10, np.random.normal(70 * weights, 25))
                        else:
                            df[col] = 0
                    
                    # ìˆ˜ì •ëœ íŒŒì¼ ì €ì¥
                    df.to_csv(grid_file, index=False, encoding='utf-8-sig')
                    print(f"   ğŸ’¾ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ ë³´ì • ë° ì €ì¥ ì™„ë£Œ")
                
                # í†µê³„ ì¶œë ¥
                demand_grids = (df['demand_score'] > 0).sum()
                supply_grids = (df['supply_score'] > 0).sum()
                print(f"   ğŸ“ˆ ìˆ˜ìš” ê²©ì: {demand_grids:,}ê°œ")
                print(f"   ğŸ“¦ ê³µê¸‰ ê²©ì: {supply_grids:,}ê°œ")
                
                return True
                
            else:
                print("   âŒ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                return self._create_default_grid_system()
                
        except Exception as e:
            print(f"   âŒ ê²©ì ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_default_grid_system()
    
    def _create_default_grid_system(self):
        """ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± (mg ë¸Œëœì¹˜ ê¸°ë³¸ + ycnham ê°œì„ )"""
        try:
            print("   ğŸ—ºï¸ ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì¤‘...")
            
            # ì„œìš¸ ì˜ì—­ ì •ì˜
            seoul_bounds = {
                'min_lat': 37.4269, 'max_lat': 37.7019,
                'min_lon': 126.7342, 'max_lon': 127.2692
            }
            
            grid_size = 0.005  # ì•½ 500m ê°„ê²©
            
            # ê²©ì ì¢Œí‘œ ìƒì„±
            lats = np.arange(seoul_bounds['min_lat'], seoul_bounds['max_lat'], grid_size)
            lons = np.arange(seoul_bounds['min_lon'], seoul_bounds['max_lon'], grid_size)
            
            grid_data = []
            
            for i, lat in enumerate(lats):
                for j, lon in enumerate(lons):
                    # ì„œìš¸ ì¤‘ì‹¬ë¶€ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ìˆ˜ìš”/ê³µê¸‰
                    seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
                    distance_to_center = np.sqrt((lat - seoul_center_lat)**2 + (lon - seoul_center_lon)**2)
                    
                    # ê±°ë¦¬ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (ì¤‘ì‹¬ë¶€ì¼ìˆ˜ë¡ ë†’ìŒ) - ycnham ê°œì„  ë°©ì‹ ì ìš©
                    center_weight = max(0.1, 1 - distance_to_center * 8)
                    
                    grid_data.append({
                        'grid_id': f'GRID_{i:03d}_{j:03d}',
                        'grid_x': i,
                        'grid_y': j,
                        'center_lat': lat + grid_size/2,
                        'center_lon': lon + grid_size/2,
                        'demand_score': max(0, np.random.normal(25 * center_weight, 15)),
                        'supply_score': max(10, np.random.normal(70 * center_weight, 30))
                    })
            
            df = pd.DataFrame(grid_data)
            
            # íŒŒì¼ ì €ì¥
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            df.to_csv(grid_file, index=False, encoding='utf-8-sig')
            
            print(f"   âœ… ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ: {len(df):,}ê°œ ê²©ì")
            return True
            
        except Exception as e:
            print(f"   âŒ ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _prepare_grid_features_improved(self):
        """ê°œì„ ëœ grid_features.csv ìƒì„± (ycnham ë¸Œëœì¹˜ ê³ ê¸‰ ê¸°ëŠ¥)"""
        try:
            # ê²©ì ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”©
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            
            if not grid_file.exists():
                print("   âŒ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            grid_df = pd.read_csv(grid_file)
            print(f"   ğŸ“Š ê²©ì ë°ì´í„° ë¡œë”©: {len(grid_df):,}í–‰")
            
            # ê°œì„ ëœ ìˆ˜ìš” ì ìˆ˜ ê³„ì‚°ê¸° ì´ˆê¸°í™”
            demand_calculator = ImprovedDemandScoreCalculator(self.processed_dir)
            
            print("   ğŸ”„ ê°œì„ ëœ ìˆ˜ìš” ì ìˆ˜ ê³„ì‚°ê¸° ë¡œë”©...")
            if not demand_calculator.load_data():
                print("   âš ï¸ ì¼ë¶€ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ê³„ì† ì§„í–‰...")
            
            # ì „ì²´ì ì¸ ë³´ì • ê³„ìˆ˜ë“¤ ê³„ì‚°
            time_factor = demand_calculator.calculate_time_pattern_factor()
            print(f"   ğŸ“ˆ ì‹œê°„ íŒ¨í„´ ë³´ì • ê³„ìˆ˜: {time_factor:.2f}")
            
            # ê²©ìë³„ íŠ¹ì„± ê³„ì‚°
            features_list = []
            total_grids = len(grid_df)
            
            for idx, grid in grid_df.iterrows():
                # ì§„í–‰ë¥  í‘œì‹œ (1000ê°œë§ˆë‹¤)
                if idx % 1000 == 0 and idx > 0:
                    progress = idx / total_grids * 100
                    print(f"   ì§„í–‰ë¥ : {progress:.1f}% ({idx:,}/{total_grids:,})")
                
                lat, lon = grid['center_lat'], grid['center_lon']
                
                # 1. ì‹¤ì œ ì¶©ì „ ìˆ˜ìš” ê³„ì‚°
                charging_demand = demand_calculator.calculate_actual_charging_demand(lat, lon)
                
                # 2. ìƒì—…ì‹œì„¤ ê¸°ë°˜ ìˆ˜ìš” ê³„ì‚°
                commercial_demand, commercial_count = demand_calculator.calculate_commercial_demand(lat, lon)
                
                # 3. ì „ê¸°ì°¨ ë“±ë¡ ë³´ì • ê³„ìˆ˜
                ev_factor = demand_calculator.calculate_ev_registration_factor(lat, lon)
                
                # 4. ì ‘ê·¼ì„± ì ìˆ˜
                accessibility = demand_calculator.calculate_accessibility_score(lat, lon)
                
                # 5. ì¢…í•© ìˆ˜ìš” ì ìˆ˜ ê³„ì‚°
                # ê°€ì¤‘ í‰ê· : ì‹¤ì œì¶©ì „(40%) + ìƒì—…ì‹œì„¤(35%) + ì ‘ê·¼ì„±(25%)
                base_demand = (
                    charging_demand * 0.40 +
                    commercial_demand * 0.35 +
                    accessibility * 0.25
                )
                
                # ë³´ì • ê³„ìˆ˜ ì ìš©
                final_demand = base_demand * ev_factor * time_factor
                
                # 0-100 ë²”ìœ„ë¡œ ì •ê·œí™”
                final_demand = max(0, min(100, final_demand))
                
                # ì¶©ì „ì†Œ ìˆ˜ ê³„ì‚°
                station_count = self._safe_count_stations(lat, lon)
                
                # ê²©ì íŠ¹ì„± ì •ë³´ (ycnham ê³ ê¸‰ + mg ê¸°ë³¸ ëª¨ë‘ í¬í•¨)
                grid_features = {
                    'grid_id': grid['grid_id'],
                    'center_lat': lat,
                    'center_lon': lon,
                    'demand_score': round(final_demand, 2),
                    'supply_score': float(grid.get('supply_score', 50)),
                    'commercial_count': commercial_count,
                    'station_count': station_count,
                    'supply_demand_ratio': 0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                    'population_density': commercial_count * 15,  # ìƒì—…ì‹œì„¤ ê¸°ë°˜ ì¶”ì •
                    'accessibility_score': round(accessibility, 2),
                    'transport_score': min(100, accessibility + np.random.uniform(-10, 10)),
                    
                    # ycnham ë¸Œëœì¹˜ì˜ ìƒˆë¡œìš´ ìˆ˜ìš” ë¶„ì„ ì»¬ëŸ¼ë“¤
                    'charging_demand_component': round(charging_demand, 2),
                    'commercial_demand_component': round(commercial_demand, 2),
                    'ev_registration_factor': round(ev_factor, 2),
                    'time_pattern_factor': round(time_factor, 2)
                }
                
                features_list.append(grid_features)
            
            # DataFrame ìƒì„±
            features_df = pd.DataFrame(features_list)
            
            # supply_demand_ratio ê³„ì‚°
            features_df['supply_demand_ratio'] = features_df.apply(
                lambda row: row['demand_score'] / max(row['supply_score'], 1), axis=1
            )
            
            # ë°ì´í„° íƒ€ì… ì •ë¦¬ ë° ê²°ì¸¡ê°’ ì²˜ë¦¬
            numeric_columns = ['demand_score', 'supply_score', 'commercial_count', 'station_count', 
                             'supply_demand_ratio', 'population_density', 'accessibility_score', 'transport_score',
                             'charging_demand_component', 'commercial_demand_component', 'ev_registration_factor', 'time_pattern_factor']
            
            for col in numeric_columns:
                if col in features_df.columns:
                    features_df[col] = pd.to_numeric(features_df[col], errors='coerce').fillna(0)
            
            # íŒŒì¼ ì €ì¥
            output_file = self.output_dir / 'grid_features.csv'
            features_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            # í†µê³„ ìš”ì•½
            print(f"   ğŸ’¾ ê°œì„ ëœ ê²©ì íŠ¹ì„± íŒŒì¼ ì €ì¥: {output_file}")
            print(f"   ğŸ“Š ì´ ê²©ì: {len(features_df):,}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ìˆ˜ìš” ì ìˆ˜: {features_df['demand_score'].mean():.2f}")
            print(f"   ğŸ“Š ìˆ˜ìš” ì ìˆ˜ ë²”ìœ„: {features_df['demand_score'].min():.2f} ~ {features_df['demand_score'].max():.2f}")
            print(f"   ğŸ“Š 0ì´ ì•„ë‹Œ ìˆ˜ìš” ê²©ì: {(features_df['demand_score'] > 0).sum():,}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ìƒì—…ì‹œì„¤ ìˆ˜: {features_df['commercial_count'].mean():.1f}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ì¶©ì „ì†Œ ìˆ˜: {features_df['station_count'].mean():.1f}ê°œ")
            
            # ìˆ˜ìš” ë¶„í¬ ì¶œë ¥
            print(f"   ğŸ“ˆ ìˆ˜ìš” ì ìˆ˜ ë¶„í¬:")
            print(f"      ğŸ”¹ 0-20: {((features_df['demand_score'] >= 0) & (features_df['demand_score'] < 20)).sum():,}ê°œ")
            print(f"      ğŸ”¹ 20-40: {((features_df['demand_score'] >= 20) & (features_df['demand_score'] < 40)).sum():,}ê°œ")
            print(f"      ğŸ”¹ 40-60: {((features_df['demand_score'] >= 40) & (features_df['demand_score'] < 60)).sum():,}ê°œ")
            print(f"      ğŸ”¹ 60-80: {((features_df['demand_score'] >= 60) & (features_df['demand_score'] < 80)).sum():,}ê°œ")
            print(f"      ğŸ”¹ 80-100: {(features_df['demand_score'] >= 80).sum():,}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ê°œì„ ëœ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            print("   ğŸ”„ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„...")
            return self._prepare_grid_features_original()
    
    def _prepare_grid_features_original(self):
        """ê¸°ì¡´ ë°©ì‹ì˜ grid_features.csv ìƒì„± (mg ë¸Œëœì¹˜ ë°©ì‹ + ë°±ì—…ìš©)"""
        try:
            # ê²©ì ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”©
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            
            if not grid_file.exists():
                print("   âŒ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            grid_df = pd.read_csv(grid_file)
            print(f"   ğŸ“Š ê²©ì ë°ì´í„° ë¡œë”© (ê¸°ì¡´ ë°©ì‹): {len(grid_df):,}í–‰")
            
            # ê²©ìë³„ íŠ¹ì„± ê³„ì‚°
            features_list = []
            total_grids = len(grid_df)
            
            for idx, grid in grid_df.iterrows():
                # ì§„í–‰ë¥  í‘œì‹œ (1000ê°œë§ˆë‹¤)
                if idx % 1000 == 0 and idx > 0:
                    progress = idx / total_grids * 100
                    print(f"   ì§„í–‰ë¥ : {progress:.1f}% ({idx:,}/{total_grids:,})")
                
                # ê¸°ë³¸ ê²©ì ì •ë³´ (mg ë¸Œëœì¹˜ ë°©ì‹)
                grid_features = {
                    'grid_id': grid['grid_id'],
                    'center_lat': grid['center_lat'],
                    'center_lon': grid['center_lon'],
                    'demand_score': float(grid.get('demand_score', 0)),  # ìˆ˜ìš” ì ìˆ˜
                    'supply_score': float(grid.get('supply_score', 0))   # ê³µê¸‰ ì ìˆ˜
                }
                
                # ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚° (ì•ˆì „í•œ ë°©ì‹)
                commercial_count = self._safe_count_commercial(
                    grid['center_lat'], grid['center_lon']
                )
                grid_features['commercial_count'] = commercial_count
                
                # ì¶©ì „ì†Œ ìˆ˜ ê³„ì‚° (ì•ˆì „í•œ ë°©ì‹)
                station_count = self._safe_count_stations(
                    grid['center_lat'], grid['center_lon']
                )
                grid_features['station_count'] = station_count
                
                # ìˆ˜ìš”-ê³µê¸‰ ë¹„ìœ¨ ê³„ì‚°
                supply_safe = max(1, grid_features['supply_score'])  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                grid_features['supply_demand_ratio'] = grid_features['demand_score'] / supply_safe
                
                # ì¸êµ¬ ë°€ë„ ì¶”ì • (ìƒì—…ì‹œì„¤ ìˆ˜ ê¸°ë°˜)
                grid_features['population_density'] = commercial_count * 12  # ê³„ìˆ˜ ì¡°ì •
                
                # ì„œìš¸ ì¤‘ì‹¬ë¶€ì™€ì˜ ê±°ë¦¬ ê¸°ë°˜ ì ‘ê·¼ì„± ì ìˆ˜
                seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
                distance = np.sqrt(
                    (grid['center_lat'] - seoul_center_lat)**2 + 
                    (grid['center_lon'] - seoul_center_lon)**2
                )
                # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ (0-100)
                grid_features['accessibility_score'] = max(0, 100 - distance * 800)
                
                # êµí†µ ì ‘ê·¼ì„± ì ìˆ˜ (ëœë¤ + ì¤‘ì‹¬ë¶€ ê°€ì¤‘ì¹˜)
                center_bonus = max(0, 50 - distance * 400)
                grid_features['transport_score'] = min(100, np.random.uniform(20, 80) + center_bonus)
                
                features_list.append(grid_features)
            
            # DataFrame ìƒì„±
            features_df = pd.DataFrame(features_list)
            
            # ë°ì´í„° íƒ€ì… ì •ë¦¬ ë° ê²°ì¸¡ê°’ ì²˜ë¦¬
            numeric_columns = ['demand_score', 'supply_score', 'commercial_count', 'station_count', 
                             'supply_demand_ratio', 'population_density', 'accessibility_score', 'transport_score']
            
            for col in numeric_columns:
                if col in features_df.columns:
                    features_df[col] = pd.to_numeric(features_df[col], errors='coerce').fillna(0)
            
            # ë°±ì—… íŒŒì¼ë¡œ ì €ì¥
            output_file = self.output_dir / 'grid_features_backup.csv'
            features_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            # í†µê³„ ìš”ì•½
            print(f"   ğŸ’¾ ê²©ì íŠ¹ì„± ë°±ì—… íŒŒì¼ ì €ì¥: {output_file}")
            print(f"   ğŸ“Š ì´ ê²©ì: {len(features_df):,}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ìˆ˜ìš” ì ìˆ˜: {features_df['demand_score'].mean():.2f}")
            print(f"   ğŸ“Š í‰ê·  ê³µê¸‰ ì ìˆ˜: {features_df['supply_score'].mean():.2f}")
            print(f"   ğŸ“Š í‰ê·  ìƒì—…ì‹œì„¤ ìˆ˜: {features_df['commercial_count'].mean():.1f}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ì¶©ì „ì†Œ ìˆ˜: {features_df['station_count'].mean():.1f}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ê¸°ì¡´ ë°©ì‹ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„±ë„ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _safe_count_commercial(self, center_lat, center_lon, radius=0.005):
        """ì•ˆì „í•œ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚° (ycnham + mg í†µí•©)"""
        try:
            commercial_file = self.processed_dir / 'commercial_facilities_processed.csv'
            if not commercial_file.exists():
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì •ê°’ ë°˜í™˜
                return self._estimate_commercial_by_location(center_lat, center_lon)
            
            # íŒŒì¼ í¬ê¸° ì²´í¬ (ë„ˆë¬´ í¬ë©´ ìƒ˜í”Œë§) - ycnham ë°©ì‹
            file_size_mb = commercial_file.stat().st_size / (1024 * 1024)
            
            if file_size_mb > 200:  # 200MB ì´ìƒì´ë©´ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                return self._count_commercial_chunked(commercial_file, center_lat, center_lon, radius)
            else:
                df = pd.read_csv(commercial_file)
                return self._count_commercial_direct(df, center_lat, center_lon, radius)
                
        except Exception:
            # ëª¨ë“  ì˜ˆì™¸ ìƒí™©ì—ì„œ ì¶”ì •ê°’ ë°˜í™˜
            return self._estimate_commercial_by_location(center_lat, center_lon)
    
    def _count_commercial_chunked(self, file_path, center_lat, center_lon, radius):
        """ì²­í¬ ë‹¨ìœ„ë¡œ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚° (ycnham ë°©ì‹)"""
        try:
            total_count = 0
            chunk_size = 50000
            
            for chunk in pd.read_csv(file_path, chunksize=chunk_size):
                if 'ê²½ë„' in chunk.columns and 'ìœ„ë„' in chunk.columns:
                    lat_diff = abs(chunk['ìœ„ë„'] - center_lat)
                    lon_diff = abs(chunk['ê²½ë„'] - center_lon)
                    nearby = (lat_diff <= radius) & (lon_diff <= radius)
                    total_count += nearby.sum()
                    
            return min(total_count, 200)  # ìµœëŒ€ê°’ ì œí•œ
        except:
            return self._estimate_commercial_by_location(center_lat, center_lon)
    
    def _count_commercial_direct(self, df, center_lat, center_lon, radius):
        """ì§ì ‘ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚° (mg + ycnham ê³µí†µ)"""
        try:
            if 'ê²½ë„' in df.columns and 'ìœ„ë„' in df.columns:
                lat_diff = abs(df['ìœ„ë„'] - center_lat)
                lon_diff = abs(df['ê²½ë„'] - center_lon)
                nearby = (lat_diff <= radius) & (lon_diff <= radius)
                return min(nearby.sum(), 200)  # ìµœëŒ€ê°’ ì œí•œ
            return 0
        except:
            return self._estimate_commercial_by_location(center_lat, center_lon)
    
    def _estimate_commercial_by_location(self, center_lat, center_lon):
        """ìœ„ì¹˜ ê¸°ë°˜ ìƒì—…ì‹œì„¤ ìˆ˜ ì¶”ì • (mg + ycnham ê³µí†µ)"""
        # ì„œìš¸ ì£¼ìš” ìƒê¶Œ ì¤‘ì‹¬ë¶€ë“¤
        major_centers = [
            (37.5665, 126.9780),  # ëª…ë™/ì¤‘êµ¬
            (37.5173, 127.0473),  # ê°•ë‚¨ì—­
            (37.5407, 127.0700),  # í™ëŒ€
            (37.4837, 127.0324),  # ì„œì´ˆ
            (37.5145, 127.1065),  # ì ì‹¤/ì†¡íŒŒ
        ]
        
        min_distance = float('inf')
        for center_lat_ref, center_lon_ref in major_centers:
            distance = np.sqrt((center_lat - center_lat_ref)**2 + (center_lon - center_lon_ref)**2)
            min_distance = min(min_distance, distance)
        
        # ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ìƒì—…ì‹œì„¤ ë°€ë„
        if min_distance < 0.01:  # 1km ì´ë‚´
            return np.random.randint(80, 150)
        elif min_distance < 0.02:  # 2km ì´ë‚´
            return np.random.randint(40, 80)
        elif min_distance < 0.05:  # 5km ì´ë‚´
            return np.random.randint(10, 40)
        else:
            return np.random.randint(0, 15)
    
    def _safe_count_stations(self, center_lat, center_lon, radius=0.01):
        """ì•ˆì „í•œ ì¶©ì „ì†Œ ìˆ˜ ê³„ì‚° (mg + ycnham ê³µí†µ)"""
        try:
            charging_file = self.processed_dir / 'charging_stations_processed.csv'
            if not charging_file.exists():
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ë°˜í™˜
                return self._estimate_stations_by_location(center_lat, center_lon)
            
            df = pd.read_csv(charging_file)
            
            # ì„œìš¸ ì§€ì—­ í•„í„°ë§
            if 'ì‹œë„' in df.columns:
                seoul_df = df[df['ì‹œë„'].str.contains('ì„œìš¸', na=False)]
            else:
                seoul_df = df
            
            if len(seoul_df) == 0:
                return 0
            
            # ì¢Œí‘œ ê¸°ë°˜ ê³„ì‚°
            if 'ê²½ë„' in seoul_df.columns and 'ìœ„ë„' in seoul_df.columns:
                lat_diff = abs(seoul_df['ìœ„ë„'] - center_lat)
                lon_diff = abs(seoul_df['ê²½ë„'] - center_lon)
                nearby = (lat_diff <= radius) & (lon_diff <= radius)
                return min(nearby.sum(), 50)  # ìµœëŒ€ 50ê°œë¡œ ì œí•œ
            
            # ì¢Œí‘œê°€ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ë°˜í™˜
            return self._estimate_stations_by_location(center_lat, center_lon)
            
        except:
            return self._estimate_stations_by_location(center_lat, center_lon)
    
    def _estimate_stations_by_location(self, center_lat, center_lon):
        """ìœ„ì¹˜ ê¸°ë°˜ ì¶©ì „ì†Œ ìˆ˜ ì¶”ì • (mg + ycnham ê³µí†µ)"""
        # ì„œìš¸ ì¤‘ì‹¬ë¶€ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
        distance = np.sqrt((center_lat - seoul_center_lat)**2 + (center_lon - seoul_center_lon)**2)
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ì¶©ì „ì†Œ ë°€ë„ ì¶”ì •
        if distance < 0.02:  # 2km ì´ë‚´ (ì¤‘ì‹¬ë¶€)
            return np.random.randint(5, 15)
        elif distance < 0.05:  # 5km ì´ë‚´ (ë„ì‹¬)
            return np.random.randint(2, 8)
        elif distance < 0.1:   # 10km ì´ë‚´ (ì™¸ê³½)
            return np.random.randint(0, 5)
        else:  # 10km ì´ìƒ (ë³€ë‘ë¦¬)
            return np.random.randint(0, 2)
    
    def _prepare_demand_supply_analysis(self):
        """demand_supply_analysis.csv ìƒì„± (mg + ycnham ê³µí†µ)"""
        try:
            grid_features_file = self.output_dir / 'grid_features.csv'
            
            if not grid_features_file.exists():
                print("   âŒ grid_features.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            df = pd.read_csv(grid_features_file)
            print(f"   ğŸ“Š ê²©ì íŠ¹ì„± ë°ì´í„° ë¡œë”©: {len(df):,}í–‰")
            
            # ë¶ˆê· í˜• ì ìˆ˜ ê³„ì‚°
            df['imbalance_score'] = df['demand_score'] / (df['supply_score'] + 1)
            
            # ë¶ˆê· í˜• ì§€ì—­ ì‹ë³„
            df['is_underserved'] = df['imbalance_score'] > 2.0
            
            # ìš°ì„ ìˆœìœ„ ë“±ê¸‰ ë¶„ë¥˜
            df['priority_level'] = pd.cut(
                df['imbalance_score'], 
                bins=[0, 1, 2, 5, float('inf')], 
                labels=['Low', 'Medium', 'High', 'Critical'],
                include_lowest=True
            )
            
            # ê³ ìˆ˜ìš” ì§€ì—­ ì‹ë³„ (ìƒìœ„ 20%)
            demand_threshold = df['demand_score'].quantile(0.8)
            df['high_demand'] = df['demand_score'] > demand_threshold
            
            # ê³ ê³µê¸‰ ì§€ì—­ ì‹ë³„ (ìƒìœ„ 20%)
            supply_threshold = df['supply_score'].quantile(0.8)
            df['high_supply'] = df['supply_score'] > supply_threshold
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥
            analysis_file = self.output_dir / 'demand_supply_analysis.csv'
            df.to_csv(analysis_file, index=False, encoding='utf-8-sig')
            
            # í†µê³„ ìš”ì•½
            underserved_count = df['is_underserved'].sum()
            critical_count = (df['priority_level'] == 'Critical').sum()
            high_demand_count = df['high_demand'].sum()
            high_supply_count = df['high_supply'].sum()
            
            print(f"   ğŸ’¾ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ íŒŒì¼ ì €ì¥: {analysis_file}")
            print(f"   ğŸ“Š ë¶ˆê· í˜• ê²©ì: {underserved_count:,}ê°œ")
            print(f"   ğŸ“Š ì‹¬ê°í•œ ë¶ˆê· í˜•: {critical_count:,}ê°œ")
            print(f"   ğŸ“Š ê³ ìˆ˜ìš” ê²©ì: {high_demand_count:,}ê°œ")
            print(f"   ğŸ“Š ê³ ê³µê¸‰ ê²©ì: {high_supply_count:,}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False
    
    def _prepare_optimal_locations(self):
        """optimal_locations.csv ìƒì„± (mg + ycnham ê³µí†µ)"""
        try:
            analysis_file = self.output_dir / 'demand_supply_analysis.csv'
            
            if not analysis_file.exists():
                print("   âŒ demand_supply_analysis.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            df = pd.read_csv(analysis_file)
            print(f"   ğŸ“Š ë¶„ì„ ë°ì´í„° ë¡œë”©: {len(df):,}í–‰")
            
            # ìµœì  ìœ„ì¹˜ ì ìˆ˜ ê³„ì‚° (ì—¬ëŸ¬ ìš”ì†Œ ê°€ì¤‘í•©)
            # ì •ê·œí™”ë¥¼ ìœ„í•œ ìµœëŒ€ê°’ ê³„ì‚°
            max_commercial = max(df['commercial_count'].max(), 1)
            max_imbalance = max(df['imbalance_score'].max(), 1)
            max_demand = max(df['demand_score'].max(), 1)
            
            # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚° (0-100 ë²”ìœ„)
            df['optimization_score'] = (
                (df['imbalance_score'] / max_imbalance) * 30 +      # ë¶ˆê· í˜• ì ìˆ˜ (30%)
                (df['demand_score'] / max_demand) * 25 +            # ìˆ˜ìš” ì ìˆ˜ (25%)
                (df['commercial_count'] / max_commercial) * 20 +    # ìƒì—…ì‹œì„¤ ë°€ë„ (20%)
                (df['accessibility_score'] / 100) * 15 +           # ì ‘ê·¼ì„± (15%)
                (df['transport_score'] / 100) * 10                 # êµí†µ ì ‘ê·¼ì„± (10%)
            ) * 100
            
            # ìƒìœ„ 100ê°œ ìµœì  ìœ„ì¹˜ ì„ ì •
            top_locations = df.nlargest(100, 'optimization_score')
            
            # ê²°ê³¼ ì €ì¥
            optimal_file = self.output_dir / 'optimal_locations.csv'
            top_locations.to_csv(optimal_file, index=False, encoding='utf-8-sig')
            
            print(f"   ğŸ’¾ ìµœì  ìœ„ì¹˜ íŒŒì¼ ì €ì¥: {optimal_file}")
            print(f"   ğŸ“Š ì„ ì •ëœ ìµœì  ìœ„ì¹˜: {len(top_locations)}ê°œ")
            
            # ìƒìœ„ 5ê°œ ìœ„ì¹˜ ì¶œë ¥
            print("   ğŸ† ìƒìœ„ 5ê°œ ìµœì  ìœ„ì¹˜:")
            for idx, row in top_locations.head().iterrows():
                score = row['optimization_score']
                grid_id = row['grid_id']
                demand = row['demand_score']
                supply = row['supply_score']
                commercial = row['commercial_count']
                print(f"      {grid_id}: ì ìˆ˜ {score:.2f} (ìˆ˜ìš”:{demand:.1f}, ê³µê¸‰:{supply:.1f}, ìƒì—…:{commercial:.0f})")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_generated_data(self):
        """ìƒì„±ëœ ë°ì´í„° íŒŒì¼ë“¤ì˜ ìœ íš¨ì„± ê²€ì¦ (mg + ycnham ê³µí†µ)"""
        try:
            required_files = [
                'grid_system_processed.csv',
                'grid_features.csv', 
                'demand_supply_analysis.csv',
                'optimal_locations.csv'
            ]
            
            validation_results = {}
            
            for filename in required_files:
                file_path = self.output_dir / filename
                
                if file_path.exists():
                    try:
                        df = pd.read_csv(file_path)
                        validation_results[filename] = {
                            'exists': True,
                            'rows': len(df),
                            'columns': len(df.columns),
                            'size_mb': file_path.stat().st_size / (1024 * 1024),
                            'valid': len(df) > 0
                        }
                        print(f"   âœ… {filename}: {len(df):,}í–‰, {len(df.columns)}ì»¬ëŸ¼")
                    except Exception as e:
                        validation_results[filename] = {
                            'exists': True,
                            'valid': False,
                            'error': str(e)
                        }
                        print(f"   âŒ {filename}: íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ - {e}")
                else:
                    validation_results[filename] = {
                        'exists': False,
                        'valid': False
                    }
                    print(f"   âŒ {filename}: íŒŒì¼ ì—†ìŒ")
            
            # ê²€ì¦ ìš”ì•½
            valid_files = sum(1 for result in validation_results.values() if result.get('valid', False))
            total_files = len(required_files)
            
            print(f"   ğŸ“Š íŒŒì¼ ê²€ì¦ ê²°ê³¼: {valid_files}/{total_files}ê°œ íŒŒì¼ ìœ íš¨")
            
            return valid_files >= 3  # ìµœì†Œ 3ê°œ íŒŒì¼ì´ ìœ íš¨í•˜ë©´ ì„±ê³µ
            
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False


# ===================================================================
# ğŸ”§ í•µì‹¬ ì‹¤í–‰ í•¨ìˆ˜ë“¤ (ì´ë¦„ ë³€ê²½ ê¸ˆì§€!)
# ===================================================================

def prepare_modeling_data():
    """
    ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ ë©”ì¸ í•¨ìˆ˜ (ycnham + mg ë¸Œëœì¹˜ í†µí•©)
    âš ï¸ ì´ í•¨ìˆ˜ëª…ì€ ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”! run_preprocessing.pyì—ì„œ importí•©ë‹ˆë‹¤.
    """
    print("ğŸš€ í†µí•© ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰...")
    
    try:
        # ModelingDataPreprocessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        preprocessor = ModelingDataPreprocessor()
        
        # ëª¨ë“  ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ ì‹¤í–‰
        result = preprocessor.prepare_all_modeling_data()
        
        if result:
            print("âœ… í†µí•© ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì„±ê³µ!")
            print("ğŸ’¡ ìƒì„±ëœ íŒŒì¼ë“¤:")
            print("   ğŸ“„ grid_features.csv - ê°œì„ ëœ ìˆ˜ìš” ì ìˆ˜ê°€ í¬í•¨ëœ íŠ¹ì„± ë°ì´í„° (ycnham ê³ ê¸‰)")
            print("   ğŸ“„ grid_features_backup.csv - ê¸°ì¡´ ë°©ì‹ ë°±ì—… (mg ê¸°ë³¸)")
            print("   ğŸ“„ demand_supply_analysis.csv - ìˆ˜ìš”-ê³µê¸‰ ë¶ˆê· í˜• ë¶„ì„")
            print("   ğŸ“„ optimal_locations.csv - ìµœì  ì¶©ì „ì†Œ ìœ„ì¹˜ í›„ë³´")
            print("ğŸ¯ í†µí•©ëœ ì£¼ìš” ê¸°ëŠ¥:")
            print("   âœ¨ ycnham: ì‹¤ì œ ì¶©ì „ëŸ‰ ë°ì´í„° ê¸°ë°˜ ìˆ˜ìš” ê³„ì‚°")
            print("   âœ¨ ycnham: ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ìƒì—…ì‹œì„¤ ë¶„ì„")
            print("   âœ¨ ycnham: ì „ê¸°ì°¨ ë“±ë¡ í˜„í™© ë°˜ì˜")
            print("   âœ¨ ycnham: ì‹œê°„ëŒ€ë³„ ì¶©ì „ íŒ¨í„´ ê³ ë ¤")
            print("   âœ¨ mg: ì•ˆì •ì ì¸ ê¸°ë³¸ ì „ì²˜ë¦¬ ë¡œì§")
            print("   âœ¨ mg: ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë°±ì—… ì‹œìŠ¤í…œ")
        else:
            print("âš ï¸ í†µí•© ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ë¶€ë¶„ ì„±ê³µ")
            print("ğŸ’¡ ì¼ë¶€ íŒŒì¼ì€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        return result
        
    except Exception as e:
        print(f"âŒ í†µí•© ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def create_modeling_preprocessor():
    """
    ModelingDataPreprocessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜ (í†µí•© ë²„ì „)
    """
    try:
        return ModelingDataPreprocessor()
    except Exception as e:
        print(f"âŒ ModelingDataPreprocessor ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def test_modeling_functions():
    """
    í†µí•© ëª¨ë¸ë§ í•¨ìˆ˜ë“¤ì˜ ì •ìƒ ì‘ë™ í…ŒìŠ¤íŠ¸
    """
    print("ğŸ§ª í†µí•© ëª¨ë¸ë§ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
    try:
        preprocessor = create_modeling_preprocessor()
        if preprocessor:
            print("âœ… ModelingDataPreprocessor ìƒì„± ì„±ê³µ")
        else:
            print("âŒ ModelingDataPreprocessor ìƒì„± ì‹¤íŒ¨")
            return False
    except Exception as e:
        print(f"âŒ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    # 2. ê°œì„ ëœ ìˆ˜ìš” ê³„ì‚°ê¸° í…ŒìŠ¤íŠ¸
    try:
        demand_calc = ImprovedDemandScoreCalculator('data/processed')
        print("âœ… ImprovedDemandScoreCalculator ìƒì„± ì„±ê³µ")
    except Exception as e:
        print(f"âš ï¸ ImprovedDemandScoreCalculator í…ŒìŠ¤íŠ¸: {e}")
    
    # 3. ë©”ì¸ í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
    try:
        print("ğŸ”§ prepare_modeling_data() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        result = prepare_modeling_data()
        if result:
            print("âœ… prepare_modeling_data() ì‹¤í–‰ ì„±ê³µ")
        else:
            print("âš ï¸ prepare_modeling_data() ë¶€ë¶„ ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âŒ ë©”ì¸ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def get_function_info():
    """
    í†µí•© ëª¨ë“ˆì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë“¤ì˜ ì •ë³´ ë°˜í™˜
    """
    functions = {
        'prepare_modeling_data': 'Main function for preparing modeling data (ycnham enhanced + mg stable)',
        'create_modeling_preprocessor': 'Create ModelingDataPreprocessor instance (unified version)',
        'test_modeling_functions': 'Test all unified modeling functions',
        'ModelingDataPreprocessor': 'Main class for modeling data preprocessing (ycnham + mg unified)',
        'ImprovedDemandScoreCalculator': 'Enhanced demand score calculation engine (ycnham advanced)'
    }
    
    print("ğŸ“‹ í†µí•© ëª¨ë¸ë§ ì „ì²˜ë¦¬ ëª¨ë“ˆ ì œê³µ í•¨ìˆ˜:")
    for func_name, description in functions.items():
        print(f"   ğŸ”§ {func_name}: {description}")
    
    print("\nğŸ¯ ë¸Œëœì¹˜ë³„ ê¸°ì—¬ë„:")
    print("   ğŸ“Š ycnham ë¸Œëœì¹˜: ê³ ê¸‰ ìˆ˜ìš” ì ìˆ˜ ê³„ì‚°, ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„")
    print("   ğŸ“Š mg ë¸Œëœì¹˜: ì•ˆì •ì ì¸ ê¸°ë³¸ ë¡œì§, ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬")
    print("   ğŸ“Š í†µí•© íš¨ê³¼: ìµœê³ ì˜ ì„±ëŠ¥ + ìµœê³ ì˜ ì•ˆì •ì„±")
    
    return functions

# ===================================================================
# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ===================================================================

def get_available_methods():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ì „ì²˜ë¦¬ ë°©ë²•ë“¤ ë°˜í™˜
    """
    methods = {
        'improved': {
            'name': 'ê°œì„ ëœ ë°©ì‹ (ycnham)',
            'description': 'ImprovedDemandScoreCalculator ì‚¬ìš©, ì‹¤ì œ ë°ì´í„° ê¸°ë°˜',
            'features': ['ì‹¤ì œ ì¶©ì „ëŸ‰ ë¶„ì„', 'ì—…ì¢…ë³„ ê°€ì¤‘ì¹˜', 'ì‹œê°„ íŒ¨í„´ ë¶„ì„', 'ì „ê¸°ì°¨ ë“±ë¡ í˜„í™©']
        },
        'original': {
            'name': 'ê¸°ì¡´ ë°©ì‹ (mg)',
            'description': 'ì•ˆì •ì ì¸ ê¸°ë³¸ ë¡œì§, ì¶”ì •ì¹˜ ê¸°ë°˜',
            'features': ['ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì •', 'ì•ˆì „í•œ ì˜¤ë¥˜ ì²˜ë¦¬', 'ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„', 'í˜¸í™˜ì„± ë³´ì¥']
        },
        'hybrid': {
            'name': 'í†µí•© ë°©ì‹ (ycnham + mg)',
            'description': 'ê°œì„ ëœ ë°©ì‹ ìš°ì„ , ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë°±ì—…',
            'features': ['ìµœê³  ì„±ëŠ¥', 'ìµœê³  ì•ˆì •ì„±', 'ì´ì¤‘ ë°±ì—…', 'ì™„ë²½ í˜¸í™˜']
        }
    }
    
    return methods

def compare_branch_differences():
    """
    ë‘ ë¸Œëœì¹˜ ê°„ì˜ ì£¼ìš” ì°¨ì´ì  ë¹„êµ
    """
    differences = {
        'ycnham_additions': [
            'ImprovedDemandScoreCalculator í´ë˜ìŠ¤',
            'ì—…ì¢…ë³„ ì „ê¸°ì°¨ ìˆ˜ìš” ê°€ì¤‘ì¹˜ ì •ì˜',
            'ì‹œê°„ëŒ€ë³„ ì¶©ì „ íŒ¨í„´ ê°€ì¤‘ì¹˜',
            'ì‹¤ì œ ì¶©ì „ëŸ‰ ê¸°ë°˜ ìˆ˜ìš” ê³„ì‚°',
            'ìƒì—…ì‹œì„¤ ì—…ì¢…ë³„ ê°€ì¤‘ ìˆ˜ìš” ê³„ì‚°',
            'ì „ê¸°ì°¨ ë“±ë¡ í˜„í™© ê¸°ë°˜ ë³´ì • ê³„ìˆ˜',
            'ì‹œê°„ëŒ€ë³„ ì¶©ì „ íŒ¨í„´ ë³´ì • ê³„ìˆ˜',
            'ì£¼ìš” êµí†µ í—ˆë¸Œ ê¸°ë°˜ ì ‘ê·¼ì„± ì ìˆ˜',
            'ì¶”ê°€ ìˆ˜ìš” ë¶„ì„ ì»¬ëŸ¼ë“¤ (charging_demand_component ë“±)',
            'ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í¬ ì²˜ë¦¬',
            'ë” ì •êµí•œ ìœ„ì¹˜ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚°'
        ],
        'mg_strengths': [
            'ì•ˆì •ì ì¸ ê¸°ë³¸ ì „ì²˜ë¦¬ ë¡œì§',
            'ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬',
            'ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°',
            'ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„',
            'ë©”ëª¨ë¦¬ íš¨ìœ¨ì ',
            'í˜¸í™˜ì„± ë³´ì¥'
        ],
        'unified_benefits': [
            'ycnhamì˜ ê³ ê¸‰ ê¸°ëŠ¥ + mgì˜ ì•ˆì •ì„±',
            'ì´ì¤‘ ë°±ì—… ì‹œìŠ¤í…œ (ê°œì„ ëœ ë°©ì‹ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹)',
            'ëª¨ë“  ê¸°ì¡´ ì½”ë“œì™€ ì™„ë²½ í˜¸í™˜',
            'ë‹¨ê³„ì  ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥',
            'ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì˜ ìµœì  ê· í˜•'
        ]
    }
    
    return differences

def validate_unified_code():
    """
    í†µí•©ëœ ì½”ë“œì˜ ìœ íš¨ì„± ê²€ì¦
    """
    validation_checks = {
        'class_definitions': ['ModelingDataPreprocessor', 'ImprovedDemandScoreCalculator'],
        'core_functions': ['prepare_modeling_data', 'create_modeling_preprocessor', 'test_modeling_functions'],
        'ycnham_features': ['_prepare_grid_features_improved', 'calculate_actual_charging_demand'],
        'mg_features': ['_prepare_grid_features_original', '_safe_count_commercial'],
        'common_features': ['_prepare_demand_supply_analysis', '_prepare_optimal_locations']
    }
    
    print("ğŸ” í†µí•© ì½”ë“œ ìœ íš¨ì„± ê²€ì¦:")
    for category, items in validation_checks.items():
        print(f"   ğŸ“‹ {category}:")
        for item in items:
            print(f"      âœ… {item}")
    
    return True

# ===================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
# ===================================================================

if __name__ == "__main__":
    print("ğŸ”§ í†µí•©ëœ modeling_data_prep.py ì§ì ‘ ì‹¤í–‰")
    print("=" * 70)
    
    # ë¸Œëœì¹˜ ì°¨ì´ì  ë¹„êµ
    print("ğŸ“Š ë¸Œëœì¹˜ í†µí•© ë¶„ì„:")
    differences = compare_branch_differences()
    
    print("\nğŸ¯ ycnham ë¸Œëœì¹˜ ì¶”ê°€ ê¸°ëŠ¥:")
    for feature in differences['ycnham_additions'][:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
        print(f"   âœ¨ {feature}")
    print(f"   ... ì´ {len(differences['ycnham_additions'])}ê°œ ê°œì„ ì‚¬í•­")
    
    print("\nğŸ’ª mg ë¸Œëœì¹˜ ê°•ì :")
    for strength in differences['mg_strengths']:
        print(f"   ğŸ›¡ï¸ {strength}")
    
    print("\nğŸš€ í†µí•© íš¨ê³¼:")
    for benefit in differences['unified_benefits']:
        print(f"   ğŸ‰ {benefit}")
    
    print("\n" + "=" * 70)
    
    # í•¨ìˆ˜ ì •ë³´ ì¶œë ¥
    get_function_info()
    
    print("\n" + "=" * 70)
    
    # ì½”ë“œ ìœ íš¨ì„± ê²€ì¦
    validate_unified_code()
    
    print("\n" + "=" * 70)
    
    # í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_result = test_modeling_functions()
    
    if test_result:
        print("\nğŸ‰ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("ğŸ’¡ ì´ì œ run_preprocessing.pyì—ì„œ ì´ í†µí•© ëª¨ë“ˆì„ ì •ìƒì ìœ¼ë¡œ importí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("ğŸ¯ ycnhamì˜ ê°œì„ ëœ demand_score + mgì˜ ì•ˆì •ì„±ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•:")
        methods = get_available_methods()
        for method_key, method_info in methods.items():
            print(f"   ğŸ”§ {method_info['name']}: {method_info['description']}")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ í•˜ì§€ë§Œ ê¸°ë³¸ì ì¸ í•¨ìˆ˜ë“¤ì€ ì •ìƒ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.")
        
    print("\nğŸŠ ycnham + mg ë¸Œëœì¹˜ í†µí•© ì™„ë£Œ!")
    print("ğŸ“ ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ì´ ë³´ì¡´ë˜ë©´ì„œ ìƒˆë¡œìš´ ê³ ê¸‰ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")