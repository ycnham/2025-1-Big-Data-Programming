# src/preprocessing/modeling_data_prep.py
# ëª¨ë¸ë§ì„ ìœ„í•œ ì™„ì „ ìˆ˜ì •ëœ ì „ì²˜ë¦¬ ì½”ë“œ

import pandas as pd
import numpy as np
from pathlib import Path
import os
import sys

# ì•ˆì „í•œ import ì²˜ë¦¬
try:
    import warnings
    warnings.filterwarnings('ignore')
except ImportError:
    pass

class ModelingDataPreprocessor:
    def __init__(self, processed_data_dir='data/processed', output_dir='data/processed'):
        """ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.project_root = self._find_project_root()
        
        # ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
        if isinstance(processed_data_dir, str):
            self.processed_dir = self.project_root / processed_data_dir
        else:
            self.processed_dir = Path(processed_data_dir)
            
        if isinstance(output_dir, str):
            self.output_dir = self.project_root / output_dir
        else:
            self.output_dir = Path(output_dir)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ”§ ëª¨ë¸ë§ ì „ì²˜ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {self.processed_dir}")
        print(f"   ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {self.output_dir}")
    
    def _find_project_root(self):
        """í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°"""
        current = Path.cwd()
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ë¶€í„° ìƒìœ„ë¡œ ì˜¬ë¼ê°€ë©° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
        while current.parent != current:
            if (current / 'src').exists() and (current / 'data').exists():
                return current
            current = current.parent
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ ë°˜í™˜
        return Path.cwd()
    
    def prepare_all_modeling_data(self):
        """ëª¨ë¸ë§ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        print("ğŸš€ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        success_count = 0
        total_steps = 5
        
        try:
            # 1. grid_system_processed.csv í™•ì¸ ë° ìƒì„±
            print("\n1ï¸âƒ£ ê²©ì ì‹œìŠ¤í…œ ë°ì´í„° ì¤€ë¹„...")
            if self._prepare_grid_system():
                success_count += 1
                print("   âœ… ê²©ì ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
            else:
                print("   âš ï¸ ê²©ì ì‹œìŠ¤í…œ ì¤€ë¹„ ë¶€ë¶„ ì„±ê³µ")
            
            # 2. grid_features.csv ìƒì„±
            print("\n2ï¸âƒ£ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„±...")
            if self._prepare_grid_features():
                success_count += 1
                print("   âœ… ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ì™„ë£Œ")
            else:
                print("   âš ï¸ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ë¶€ë¶„ ì„±ê³µ")
            
            # 3. demand_supply_analysis.csv ìƒì„±
            print("\n3ï¸âƒ£ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ë°ì´í„° ìƒì„±...")
            if self._prepare_demand_supply_analysis():
                success_count += 1
                print("   âœ… ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ì™„ë£Œ")
            else:
                print("   âš ï¸ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ë¶€ë¶„ ì„±ê³µ")
            
            # 4. optimal_locations.csv ìƒì„±
            print("\n4ï¸âƒ£ ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„±...")
            if self._prepare_optimal_locations():
                success_count += 1
                print("   âœ… ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„± ì™„ë£Œ")
            else:
                print("   âš ï¸ ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„± ë¶€ë¶„ ì„±ê³µ")
            
            # 5. ë°ì´í„° ê²€ì¦
            print("\n5ï¸âƒ£ ìƒì„±ëœ ë°ì´í„° ê²€ì¦...")
            if self._validate_generated_data():
                success_count += 1
                print("   âœ… ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
            else:
                print("   âš ï¸ ë°ì´í„° ê²€ì¦ ë¶€ë¶„ ì„±ê³µ")
            
            # ê²°ê³¼ ìš”ì•½
            success_rate = success_count / total_steps * 100
            print(f"\nğŸ“Š ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ì„±ê³µë¥ : {success_count}/{total_steps} ({success_rate:.1f}%)")
            
            if success_count >= 4:
                print("âœ… ëª¨ë¸ë§ì— í•„ìš”í•œ í•µì‹¬ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                return True
            elif success_count >= 2:
                print("âš ï¸ ê¸°ë³¸ì ì¸ ëª¨ë¸ë§ ë°ì´í„°ëŠ” ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return True
            else:
                print("âŒ ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
                return False
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _prepare_grid_system(self):
        """grid_system_processed.csv í™•ì¸ ë° ë³´ì •"""
        try:
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            
            if grid_file.exists():
                df = pd.read_csv(grid_file)
                print(f"   ğŸ“Š ê¸°ì¡´ ê²©ì íŒŒì¼ ë°œê²¬: {len(df):,}í–‰")
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì¶”ê°€
                required_cols = ['grid_id', 'center_lat', 'center_lon', 'demand_score', 'supply_score']
                missing_cols = [col for col in required_cols if col not in df.columns]
                
                if missing_cols:
                    print(f"   ğŸ”§ ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€: {missing_cols}")
                    
                    for col in missing_cols:
                        if col == 'grid_id':
                            # ê¸°ì¡´ ì»¬ëŸ¼ í™œìš©í•˜ì—¬ grid_id ìƒì„±
                            if 'grid_x' in df.columns and 'grid_y' in df.columns:
                                df['grid_id'] = df.apply(lambda row: f"GRID_{int(row['grid_x']):03d}_{int(row['grid_y']):03d}", axis=1)
                            else:
                                df['grid_id'] = [f'GRID_{i:05d}' for i in range(len(df))]
                        elif col == 'demand_score':
                            # ê¸°ì¡´ ìˆ˜ìš” ê´€ë ¨ ì»¬ëŸ¼ ë§¤í•‘
                            if 'total_demand' in df.columns:
                                df[col] = df['total_demand']
                            elif 'demand' in df.columns:
                                df[col] = df['demand']
                            else:
                                # ì •ê·œë¶„í¬ ê¸°ë°˜ ì„ì‹œ ë°ì´í„°
                                df[col] = np.maximum(0, np.random.normal(25, 15, len(df)))
                        elif col == 'supply_score':
                            # ê¸°ì¡´ ê³µê¸‰ ê´€ë ¨ ì»¬ëŸ¼ ë§¤í•‘
                            if 'total_supply' in df.columns:
                                df[col] = df['total_supply']
                            elif 'supply' in df.columns:
                                df[col] = df['supply']
                            else:
                                # ì •ê·œë¶„í¬ ê¸°ë°˜ ì„ì‹œ ë°ì´í„°
                                df[col] = np.maximum(10, np.random.normal(80, 30, len(df)))
                        else:
                            df[col] = 0
                    
                    # ìˆ˜ì •ëœ íŒŒì¼ ì €ì¥
                    df.to_csv(grid_file, index=False, encoding='utf-8-sig')
                    print(f"   ğŸ’¾ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ ë³´ì • ë° ì €ì¥ ì™„ë£Œ")
                
                # í†µê³„ ì¶œë ¥
                demand_grids = (df['demand_score'] > 0).sum()
                supply_grids = (df['supply_score'] > 0).sum()
                print(f"   ğŸ“ˆ ìˆ˜ìš” ê²©ì: {demand_grids:,}ê°œ")
                print(f"   ğŸ“¦ ê³µê¸‰ ê²©ì: {supply_grids:,}ê°œ")
                
                return True
                
            else:
                print("   âŒ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                return self._create_default_grid_system()
                
        except Exception as e:
            print(f"   âŒ ê²©ì ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_default_grid_system()
    
    def _create_default_grid_system(self):
        """ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„±"""
        try:
            print("   ğŸ—ºï¸ ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì¤‘...")
            
            # ì„œìš¸ ì˜ì—­ ì •ì˜
            seoul_bounds = {
                'min_lat': 37.4269, 'max_lat': 37.7019,
                'min_lon': 126.7342, 'max_lon': 127.2692
            }
            
            grid_size = 0.005  # ì•½ 500m ê°„ê²©
            
            # ê²©ì ì¢Œí‘œ ìƒì„±
            lats = np.arange(seoul_bounds['min_lat'], seoul_bounds['max_lat'], grid_size)
            lons = np.arange(seoul_bounds['min_lon'], seoul_bounds['max_lon'], grid_size)
            
            grid_data = []
            
            for i, lat in enumerate(lats):
                for j, lon in enumerate(lons):
                    # ì„œìš¸ ì¤‘ì‹¬ë¶€ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ìˆ˜ìš”/ê³µê¸‰
                    seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
                    distance_to_center = np.sqrt((lat - seoul_center_lat)**2 + (lon - seoul_center_lon)**2)
                    
                    # ê±°ë¦¬ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (ì¤‘ì‹¬ë¶€ì¼ìˆ˜ë¡ ë†’ìŒ)
                    center_weight = max(0.1, 1 - distance_to_center * 10)
                    
                    grid_data.append({
                        'grid_id': f'GRID_{i:03d}_{j:03d}',
                        'grid_x': i,
                        'grid_y': j,
                        'center_lat': lat + grid_size/2,
                        'center_lon': lon + grid_size/2,
                        'demand_score': max(0, np.random.normal(30 * center_weight, 20)),
                        'supply_score': max(10, np.random.normal(80 * center_weight, 40))
                    })
            
            df = pd.DataFrame(grid_data)
            
            # íŒŒì¼ ì €ì¥
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            df.to_csv(grid_file, index=False, encoding='utf-8-sig')
            
            print(f"   âœ… ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ: {len(df):,}ê°œ ê²©ì")
            return True
            
        except Exception as e:
            print(f"   âŒ ê¸°ë³¸ ê²©ì ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _prepare_grid_features(self):
        """grid_features.csv ìƒì„±"""
        try:
            # ê²©ì ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”©
            grid_file = self.processed_dir / 'grid_system_processed.csv'
            
            if not grid_file.exists():
                print("   âŒ ê²©ì ì‹œìŠ¤í…œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            grid_df = pd.read_csv(grid_file)
            print(f"   ğŸ“Š ê²©ì ë°ì´í„° ë¡œë”©: {len(grid_df):,}í–‰")
            
            # ê²©ìë³„ íŠ¹ì„± ê³„ì‚°
            features_list = []
            total_grids = len(grid_df)
            
            for idx, grid in grid_df.iterrows():
                # ì§„í–‰ë¥  í‘œì‹œ (1000ê°œë§ˆë‹¤)
                if idx % 1000 == 0 and idx > 0:
                    progress = idx / total_grids * 100
                    print(f"   ì§„í–‰ë¥ : {progress:.1f}% ({idx:,}/{total_grids:,})")
                
                # ê¸°ë³¸ ê²©ì ì •ë³´
                grid_features = {
                    'grid_id': grid['grid_id'],
                    'center_lat': grid['center_lat'],
                    'center_lon': grid['center_lon'],
                    'demand_score': float(grid.get('demand_score', 0)),  # ìˆ˜ìš” ì ìˆ˜
                    'supply_score': float(grid.get('supply_score', 0))   # ê³µê¸‰ ì ìˆ˜
                }
                
                # ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚° (ì•ˆì „í•œ ë°©ì‹)
                commercial_count = self._safe_count_commercial(
                    grid['center_lat'], grid['center_lon']
                )
                grid_features['commercial_count'] = commercial_count
                
                # ì¶©ì „ì†Œ ìˆ˜ ê³„ì‚° (ì•ˆì „í•œ ë°©ì‹)
                station_count = self._safe_count_stations(
                    grid['center_lat'], grid['center_lon']
                )
                grid_features['station_count'] = station_count
                
                # ìˆ˜ìš”-ê³µê¸‰ ë¹„ìœ¨ ê³„ì‚°
                supply_safe = max(1, grid_features['supply_score'])  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                grid_features['supply_demand_ratio'] = grid_features['demand_score'] / supply_safe
                
                # ì¸êµ¬ ë°€ë„ ì¶”ì • (ìƒì—…ì‹œì„¤ ìˆ˜ ê¸°ë°˜)
                grid_features['population_density'] = commercial_count * 12  # ê³„ìˆ˜ ì¡°ì •
                
                # ì„œìš¸ ì¤‘ì‹¬ë¶€ì™€ì˜ ê±°ë¦¬ ê¸°ë°˜ ì ‘ê·¼ì„± ì ìˆ˜
                seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
                distance = np.sqrt(
                    (grid['center_lat'] - seoul_center_lat)**2 + 
                    (grid['center_lon'] - seoul_center_lon)**2
                )
                # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ (0-100)
                grid_features['accessibility_score'] = max(0, 100 - distance * 800)
                
                # êµí†µ ì ‘ê·¼ì„± ì ìˆ˜ (ëœë¤ + ì¤‘ì‹¬ë¶€ ê°€ì¤‘ì¹˜)
                center_bonus = max(0, 50 - distance * 400)
                grid_features['transport_score'] = min(100, np.random.uniform(20, 80) + center_bonus)
                
                features_list.append(grid_features)
            
            # DataFrame ìƒì„±
            features_df = pd.DataFrame(features_list)
            
            # ë°ì´í„° íƒ€ì… ì •ë¦¬ ë° ê²°ì¸¡ê°’ ì²˜ë¦¬
            numeric_columns = ['demand_score', 'supply_score', 'commercial_count', 'station_count', 
                             'supply_demand_ratio', 'population_density', 'accessibility_score', 'transport_score']
            
            for col in numeric_columns:
                if col in features_df.columns:
                    features_df[col] = pd.to_numeric(features_df[col], errors='coerce').fillna(0)
            
            # íŒŒì¼ ì €ì¥
            output_file = self.output_dir / 'grid_features.csv'
            features_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            
            # í†µê³„ ìš”ì•½
            print(f"   ğŸ’¾ ê²©ì íŠ¹ì„± íŒŒì¼ ì €ì¥: {output_file}")
            print(f"   ğŸ“Š ì´ ê²©ì: {len(features_df):,}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ìˆ˜ìš” ì ìˆ˜: {features_df['demand_score'].mean():.2f}")
            print(f"   ğŸ“Š í‰ê·  ê³µê¸‰ ì ìˆ˜: {features_df['supply_score'].mean():.2f}")
            print(f"   ğŸ“Š í‰ê·  ìƒì—…ì‹œì„¤ ìˆ˜: {features_df['commercial_count'].mean():.1f}ê°œ")
            print(f"   ğŸ“Š í‰ê·  ì¶©ì „ì†Œ ìˆ˜: {features_df['station_count'].mean():.1f}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ê²©ì íŠ¹ì„± ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _safe_count_commercial(self, center_lat, center_lon, radius=0.005):
        """ì•ˆì „í•œ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚°"""
        try:
            commercial_file = self.processed_dir / 'commercial_facilities_processed.csv'
            if not commercial_file.exists():
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì •ê°’ ë°˜í™˜
                return self._estimate_commercial_by_location(center_lat, center_lon)
            
            # íŒŒì¼ í¬ê¸° ì²´í¬ (ë„ˆë¬´ í¬ë©´ ìƒ˜í”Œë§)
            file_size_mb = commercial_file.stat().st_size / (1024 * 1024)
            
            if file_size_mb > 200:  # 200MB ì´ìƒì´ë©´ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                return self._count_commercial_chunked(commercial_file, center_lat, center_lon, radius)
            else:
                df = pd.read_csv(commercial_file)
                return self._count_commercial_direct(df, center_lat, center_lon, radius)
                
        except Exception:
            # ëª¨ë“  ì˜ˆì™¸ ìƒí™©ì—ì„œ ì¶”ì •ê°’ ë°˜í™˜
            return self._estimate_commercial_by_location(center_lat, center_lon)
    
    def _count_commercial_chunked(self, file_path, center_lat, center_lon, radius):
        """ì²­í¬ ë‹¨ìœ„ë¡œ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚°"""
        try:
            total_count = 0
            chunk_size = 50000
            
            for chunk in pd.read_csv(file_path, chunksize=chunk_size):
                if 'ê²½ë„' in chunk.columns and 'ìœ„ë„' in chunk.columns:
                    lat_diff = abs(chunk['ìœ„ë„'] - center_lat)
                    lon_diff = abs(chunk['ê²½ë„'] - center_lon)
                    nearby = (lat_diff <= radius) & (lon_diff <= radius)
                    total_count += nearby.sum()
                    
            return min(total_count, 200)  # ìµœëŒ€ê°’ ì œí•œ
        except:
            return self._estimate_commercial_by_location(center_lat, center_lon)
    
    def _count_commercial_direct(self, df, center_lat, center_lon, radius):
        """ì§ì ‘ ìƒì—…ì‹œì„¤ ìˆ˜ ê³„ì‚°"""
        try:
            if 'ê²½ë„' in df.columns and 'ìœ„ë„' in df.columns:
                lat_diff = abs(df['ìœ„ë„'] - center_lat)
                lon_diff = abs(df['ê²½ë„'] - center_lon)
                nearby = (lat_diff <= radius) & (lon_diff <= radius)
                return min(nearby.sum(), 200)  # ìµœëŒ€ê°’ ì œí•œ
            return 0
        except:
            return self._estimate_commercial_by_location(center_lat, center_lon)
    
    def _estimate_commercial_by_location(self, center_lat, center_lon):
        """ìœ„ì¹˜ ê¸°ë°˜ ìƒì—…ì‹œì„¤ ìˆ˜ ì¶”ì •"""
        # ì„œìš¸ ì£¼ìš” ìƒê¶Œ ì¤‘ì‹¬ë¶€ë“¤
        major_centers = [
            (37.5665, 126.9780),  # ëª…ë™/ì¤‘êµ¬
            (37.5173, 127.0473),  # ê°•ë‚¨ì—­
            (37.5407, 127.0700),  # í™ëŒ€
            (37.4837, 127.0324),  # ì„œì´ˆ
            (37.5145, 127.1065),  # ì ì‹¤/ì†¡íŒŒ
        ]
        
        min_distance = float('inf')
        for center_lat_ref, center_lon_ref in major_centers:
            distance = np.sqrt((center_lat - center_lat_ref)**2 + (center_lon - center_lon_ref)**2)
            min_distance = min(min_distance, distance)
        
        # ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ìƒì—…ì‹œì„¤ ë°€ë„
        if min_distance < 0.01:  # 1km ì´ë‚´
            return np.random.randint(80, 150)
        elif min_distance < 0.02:  # 2km ì´ë‚´
            return np.random.randint(40, 80)
        elif min_distance < 0.05:  # 5km ì´ë‚´
            return np.random.randint(10, 40)
        else:
            return np.random.randint(0, 15)
    
    def _safe_count_stations(self, center_lat, center_lon, radius=0.01):
        """ì•ˆì „í•œ ì¶©ì „ì†Œ ìˆ˜ ê³„ì‚°"""
        try:
            charging_file = self.processed_dir / 'charging_stations_processed.csv'
            if not charging_file.exists():
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ë°˜í™˜
                return self._estimate_stations_by_location(center_lat, center_lon)
            
            df = pd.read_csv(charging_file)
            
            # ì„œìš¸ ì§€ì—­ í•„í„°ë§
            if 'ì‹œë„' in df.columns:
                seoul_df = df[df['ì‹œë„'].str.contains('ì„œìš¸', na=False)]
            else:
                seoul_df = df
            
            if len(seoul_df) == 0:
                return 0
            
            # ì¢Œí‘œ ê¸°ë°˜ ê³„ì‚°
            if 'ê²½ë„' in seoul_df.columns and 'ìœ„ë„' in seoul_df.columns:
                lat_diff = abs(seoul_df['ìœ„ë„'] - center_lat)
                lon_diff = abs(seoul_df['ê²½ë„'] - center_lon)
                nearby = (lat_diff <= radius) & (lon_diff <= radius)
                return min(nearby.sum(), 50)  # ìµœëŒ€ 50ê°œë¡œ ì œí•œ
            
            # ì¢Œí‘œê°€ ì—†ìœ¼ë©´ ì¶”ì •ê°’ ë°˜í™˜
            return self._estimate_stations_by_location(center_lat, center_lon)
            
        except:
            return self._estimate_stations_by_location(center_lat, center_lon)
    
    def _estimate_stations_by_location(self, center_lat, center_lon):
        """ìœ„ì¹˜ ê¸°ë°˜ ì¶©ì „ì†Œ ìˆ˜ ì¶”ì •"""
        # ì„œìš¸ ì¤‘ì‹¬ë¶€ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        seoul_center_lat, seoul_center_lon = 37.5665, 126.9780
        distance = np.sqrt((center_lat - seoul_center_lat)**2 + (center_lon - seoul_center_lon)**2)
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ì¶©ì „ì†Œ ë°€ë„ ì¶”ì •
        if distance < 0.02:  # 2km ì´ë‚´ (ì¤‘ì‹¬ë¶€)
            return np.random.randint(5, 15)
        elif distance < 0.05:  # 5km ì´ë‚´ (ë„ì‹¬)
            return np.random.randint(2, 8)
        elif distance < 0.1:   # 10km ì´ë‚´ (ì™¸ê³½)
            return np.random.randint(0, 5)
        else:  # 10km ì´ìƒ (ë³€ë‘ë¦¬)
            return np.random.randint(0, 2)
    
    def _prepare_demand_supply_analysis(self):
        """demand_supply_analysis.csv ìƒì„±"""
        try:
            grid_features_file = self.output_dir / 'grid_features.csv'
            
            if not grid_features_file.exists():
                print("   âŒ grid_features.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            df = pd.read_csv(grid_features_file)
            print(f"   ğŸ“Š ê²©ì íŠ¹ì„± ë°ì´í„° ë¡œë”©: {len(df):,}í–‰")
            
            # ë¶ˆê· í˜• ì ìˆ˜ ê³„ì‚°
            df['imbalance_score'] = df['demand_score'] / (df['supply_score'] + 1)
            
            # ë¶ˆê· í˜• ì§€ì—­ ì‹ë³„
            df['is_underserved'] = df['imbalance_score'] > 2.0
            
            # ìš°ì„ ìˆœìœ„ ë“±ê¸‰ ë¶„ë¥˜
            df['priority_level'] = pd.cut(
                df['imbalance_score'], 
                bins=[0, 1, 2, 5, float('inf')], 
                labels=['Low', 'Medium', 'High', 'Critical'],
                include_lowest=True
            )
            
            # ê³ ìˆ˜ìš” ì§€ì—­ ì‹ë³„ (ìƒìœ„ 20%)
            demand_threshold = df['demand_score'].quantile(0.8)
            df['high_demand'] = df['demand_score'] > demand_threshold
            
            # ê³ ê³µê¸‰ ì§€ì—­ ì‹ë³„ (ìƒìœ„ 20%)
            supply_threshold = df['supply_score'].quantile(0.8)
            df['high_supply'] = df['supply_score'] > supply_threshold
            
            # ë¶„ì„ ê²°ê³¼ ì €ì¥
            analysis_file = self.output_dir / 'demand_supply_analysis.csv'
            df.to_csv(analysis_file, index=False, encoding='utf-8-sig')
            
            # í†µê³„ ìš”ì•½
            underserved_count = df['is_underserved'].sum()
            critical_count = (df['priority_level'] == 'Critical').sum()
            high_demand_count = df['high_demand'].sum()
            high_supply_count = df['high_supply'].sum()
            
            print(f"   ğŸ’¾ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ íŒŒì¼ ì €ì¥: {analysis_file}")
            print(f"   ğŸ“Š ë¶ˆê· í˜• ê²©ì: {underserved_count:,}ê°œ")
            print(f"   ğŸ“Š ì‹¬ê°í•œ ë¶ˆê· í˜•: {critical_count:,}ê°œ")
            print(f"   ğŸ“Š ê³ ìˆ˜ìš” ê²©ì: {high_demand_count:,}ê°œ")
            print(f"   ğŸ“Š ê³ ê³µê¸‰ ê²©ì: {high_supply_count:,}ê°œ")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ìˆ˜ìš”-ê³µê¸‰ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False
    
    def _prepare_optimal_locations(self):
        """optimal_locations.csv ìƒì„±"""
        try:
            analysis_file = self.output_dir / 'demand_supply_analysis.csv'
            
            if not analysis_file.exists():
                print("   âŒ demand_supply_analysis.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                return False
            
            df = pd.read_csv(analysis_file)
            print(f"   ğŸ“Š ë¶„ì„ ë°ì´í„° ë¡œë”©: {len(df):,}í–‰")
            
            # ìµœì  ìœ„ì¹˜ ì ìˆ˜ ê³„ì‚° (ì—¬ëŸ¬ ìš”ì†Œ ê°€ì¤‘í•©)
            # ì •ê·œí™”ë¥¼ ìœ„í•œ ìµœëŒ€ê°’ ê³„ì‚°
            max_commercial = max(df['commercial_count'].max(), 1)
            max_imbalance = max(df['imbalance_score'].max(), 1)
            max_demand = max(df['demand_score'].max(), 1)
            
            # ê°€ì¤‘ ì ìˆ˜ ê³„ì‚° (0-100 ë²”ìœ„)
            df['optimization_score'] = (
                (df['imbalance_score'] / max_imbalance) * 30 +      # ë¶ˆê· í˜• ì ìˆ˜ (30%)
                (df['demand_score'] / max_demand) * 25 +            # ìˆ˜ìš” ì ìˆ˜ (25%)
                (df['commercial_count'] / max_commercial) * 20 +    # ìƒì—…ì‹œì„¤ ë°€ë„ (20%)
                (df['accessibility_score'] / 100) * 15 +           # ì ‘ê·¼ì„± (15%)
                (df['transport_score'] / 100) * 10                 # êµí†µ ì ‘ê·¼ì„± (10%)
            ) * 100
            
            # ìƒìœ„ 100ê°œ ìµœì  ìœ„ì¹˜ ì„ ì •
            top_locations = df.nlargest(100, 'optimization_score')
            
            # ê²°ê³¼ ì €ì¥
            optimal_file = self.output_dir / 'optimal_locations.csv'
            top_locations.to_csv(optimal_file, index=False, encoding='utf-8-sig')
            
            print(f"   ğŸ’¾ ìµœì  ìœ„ì¹˜ íŒŒì¼ ì €ì¥: {optimal_file}")
            print(f"   ğŸ“Š ì„ ì •ëœ ìµœì  ìœ„ì¹˜: {len(top_locations)}ê°œ")
            
            # ìƒìœ„ 5ê°œ ìœ„ì¹˜ ì¶œë ¥
            print("   ğŸ† ìƒìœ„ 5ê°œ ìµœì  ìœ„ì¹˜:")
            for idx, row in top_locations.head().iterrows():
                score = row['optimization_score']
                grid_id = row['grid_id']
                demand = row['demand_score']
                supply = row['supply_score']
                commercial = row['commercial_count']
                print(f"      {grid_id}: ì ìˆ˜ {score:.2f} (ìˆ˜ìš”:{demand:.1f}, ê³µê¸‰:{supply:.1f}, ìƒì—…:{commercial:.0f})")
            
            return True
            
        except Exception as e:
            print(f"   âŒ ìµœì  ìœ„ì¹˜ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_generated_data(self):
        """ìƒì„±ëœ ë°ì´í„° íŒŒì¼ë“¤ì˜ ìœ íš¨ì„± ê²€ì¦"""
        try:
            required_files = [
                'grid_system_processed.csv',
                'grid_features.csv', 
                'demand_supply_analysis.csv',
                'optimal_locations.csv'
            ]
            
            validation_results = {}
            
            for filename in required_files:
                file_path = self.output_dir / filename
                
                if file_path.exists():
                    try:
                        df = pd.read_csv(file_path)
                        validation_results[filename] = {
                            'exists': True,
                            'rows': len(df),
                            'columns': len(df.columns),
                            'size_mb': file_path.stat().st_size / (1024 * 1024),
                            'valid': len(df) > 0
                        }
                        print(f"   âœ… {filename}: {len(df):,}í–‰, {len(df.columns)}ì»¬ëŸ¼")
                    except Exception as e:
                        validation_results[filename] = {
                            'exists': True,
                            'valid': False,
                            'error': str(e)
                        }
                        print(f"   âŒ {filename}: íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ - {e}")
                else:
                    validation_results[filename] = {
                        'exists': False,
                        'valid': False
                    }
                    print(f"   âŒ {filename}: íŒŒì¼ ì—†ìŒ")
            
            # ê²€ì¦ ìš”ì•½
            valid_files = sum(1 for result in validation_results.values() if result.get('valid', False))
            total_files = len(required_files)
            
            print(f"   ğŸ“Š íŒŒì¼ ê²€ì¦ ê²°ê³¼: {valid_files}/{total_files}ê°œ íŒŒì¼ ìœ íš¨")
            
            return valid_files >= 3  # ìµœì†Œ 3ê°œ íŒŒì¼ì´ ìœ íš¨í•˜ë©´ ì„±ê³µ
            
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False


# ===================================================================
# ğŸ”§ í•µì‹¬ ì‹¤í–‰ í•¨ìˆ˜ë“¤ (ì´ë¦„ ë³€ê²½ ê¸ˆì§€!)
# ===================================================================

def prepare_modeling_data():
    """
    ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ ë©”ì¸ í•¨ìˆ˜
    âš ï¸ ì´ í•¨ìˆ˜ëª…ì€ ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”! run_preprocessing.pyì—ì„œ importí•©ë‹ˆë‹¤.
    """
    print("ğŸš€ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰...")
    
    try:
        # ModelingDataPreprocessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        preprocessor = ModelingDataPreprocessor()
        
        # ëª¨ë“  ëª¨ë¸ë§ ë°ì´í„° ì¤€ë¹„ ì‹¤í–‰
        result = preprocessor.prepare_all_modeling_data()
        
        if result:
            print("âœ… ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì„±ê³µ!")
            print("ğŸ’¡ ìƒì„±ëœ íŒŒì¼ë“¤:")
            print("   ğŸ“„ grid_features.csv - ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµìš© íŠ¹ì„± ë°ì´í„°")
            print("   ğŸ“„ demand_supply_analysis.csv - ìˆ˜ìš”-ê³µê¸‰ ë¶ˆê· í˜• ë¶„ì„")
            print("   ğŸ“„ optimal_locations.csv - ìµœì  ì¶©ì „ì†Œ ìœ„ì¹˜ í›„ë³´")
        else:
            print("âš ï¸ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ë¶€ë¶„ ì„±ê³µ")
            print("ğŸ’¡ ì¼ë¶€ íŒŒì¼ì€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        return result
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def create_modeling_preprocessor():
    """
    ModelingDataPreprocessor ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í•¨ìˆ˜
    """
    try:
        return ModelingDataPreprocessor()
    except Exception as e:
        print(f"âŒ ModelingDataPreprocessor ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def test_modeling_functions():
    """
    ëª¨ë¸ë§ í•¨ìˆ˜ë“¤ì˜ ì •ìƒ ì‘ë™ í…ŒìŠ¤íŠ¸
    """
    print("ğŸ§ª ëª¨ë¸ë§ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # 1. í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
    try:
        preprocessor = create_modeling_preprocessor()
        if preprocessor:
            print("âœ… ModelingDataPreprocessor ìƒì„± ì„±ê³µ")
        else:
            print("âŒ ModelingDataPreprocessor ìƒì„± ì‹¤íŒ¨")
            return False
    except Exception as e:
        print(f"âŒ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    # 2. ë©”ì¸ í•¨ìˆ˜ í˜¸ì¶œ í…ŒìŠ¤íŠ¸
    try:
        print("ğŸ”§ prepare_modeling_data() í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...")
        result = prepare_modeling_data()
        if result:
            print("âœ… prepare_modeling_data() ì‹¤í–‰ ì„±ê³µ")
        else:
            print("âš ï¸ prepare_modeling_data() ë¶€ë¶„ ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âŒ ë©”ì¸ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def get_function_info():
    """
    ì´ ëª¨ë“ˆì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë“¤ì˜ ì •ë³´ ë°˜í™˜
    """
    functions = {
        'prepare_modeling_data': 'Main function for preparing modeling data',
        'create_modeling_preprocessor': 'Create ModelingDataPreprocessor instance',
        'test_modeling_functions': 'Test all modeling functions',
        'ModelingDataPreprocessor': 'Main class for modeling data preprocessing'
    }
    
    print("ğŸ“‹ ëª¨ë¸ë§ ì „ì²˜ë¦¬ ëª¨ë“ˆ ì œê³µ í•¨ìˆ˜:")
    for func_name, description in functions.items():
        print(f"   ğŸ”§ {func_name}: {description}")
    
    return functions

# ===================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
# ===================================================================

if __name__ == "__main__":
    print("ğŸ”§ modeling_data_prep.py ì§ì ‘ ì‹¤í–‰")
    print("=" * 60)
    
    # í•¨ìˆ˜ ì •ë³´ ì¶œë ¥
    get_function_info()
    
    print("\n" + "=" * 60)
    
    # í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_result = test_modeling_functions()
    
    if test_result:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("ğŸ’¡ ì´ì œ run_preprocessing.pyì—ì„œ ì´ ëª¨ë“ˆì„ ì •ìƒì ìœ¼ë¡œ importí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ í•˜ì§€ë§Œ ê¸°ë³¸ì ì¸ í•¨ìˆ˜ë“¤ì€ ì •ìƒ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.")
