# src/preprocessing/data_loader.py

import pandas as pd
import numpy as np
import os
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataLoader:
    def __init__(self, data_dir='data/raw'):
        self.data_dir = Path(data_dir)
        self.datasets = {}
        
    def load_all_datasets(self):
        """ëª¨ë“  ë°ì´í„°ì…‹ì„ ë¡œë”©í•©ë‹ˆë‹¤."""
        print("ğŸš€ ëª¨ë“  ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("=" * 60)
        print("ğŸš€ ë°ì´í„° ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print()
        
        # ë¡œë”©í•  ë°ì´í„°ì…‹ ì •ì˜
        dataset_configs = {
            'charging_load_hourly': {
                'file': 'ì„œìš¸ì‹œ ì†Œìœ  ì¶©ì „ê¸° ì¼ë³„ ì‹œê°„ë³„ ì¶©ì „í˜„í™©.xlsx',
                'description': 'ì„œìš¸ì‹œ ì†Œìœ  ì¶©ì „ê¸° ì‹œê°„ë³„ ì¶©ì „í˜„í™©'
            },
            'ev_registration_monthly': {
                'file': 'ì„œìš¸ì‹œ ìì¹˜êµ¬ ìë©´ë™ë³„ ì—°ë£Œë³„ ìë™ì°¨ ë“±ë¡í˜„í™©(í–‰ì •ë™)(25ë…„04ì›”).xls',
                'description': 'ì„œìš¸ì‹œ ìì¹˜êµ¬ë³„ ì „ê¸°ì°¨ ë“±ë¡í˜„í™© (2025ë…„ 4ì›”)'
            },
            'commercial_facilities': {
                'file': 'ì†Œìƒê³µì¸ì‹œì¥ì§„í¥ê³µë‹¨_ìƒê°€(ìƒê¶Œ)ì •ë³´_ì„œìš¸_202503.csv',
                'description': 'ì„œìš¸ì‹œ ìƒê°€(ìƒê¶Œ) ì •ë³´ (2025ë…„ 3ì›”)'
            },
            'charging_stations_202501': {
                'file': 'ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„°_202501.xlsx',
                'description': 'ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„° (2025ë…„ 1ì›”)'
            },
            'charging_stations_202502': {
                'file': 'ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„°_202502.xlsx',
                'description': 'ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„° (2025ë…„ 2ì›”)'
            },
            'charging_stations_202503': {
                'file': 'ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„°_202503.xlsx',
                'description': 'ì „ê¸°ì°¨ ì¶©ì „ì†Œ ì¶©ì „ëŸ‰ ë°ì´í„° (2025ë…„ 3ì›”)'
            }
        }
        
        # ì„ íƒì ìœ¼ë¡œ ë¡œë”©í•  ë°ì´í„°ì…‹
        optional_datasets = {
            'ev_charging_service': {
                'file': '(ì°¸ê³ ìë£Œ) í•œêµ­ì „ë ¥ê³µì‚¬_ì „ê¸°ì°¨ì¶©ì „ì„œë¹„ìŠ¤ìš´ì˜ì‹œìŠ¤í…œ_ê³ ê°ì„¼í„° ìƒë‹´ë‚´ì—­_ì½”ë“œí‘œ.xlsx',
                'description': 'ì „ê¸°ì°¨ ì¶©ì „ì„œë¹„ìŠ¤ ì½”ë“œí‘œ (ì°¸ê³ ìë£Œ)'
            },
            'public_parking': {
                'file': 'ì›”ë³„ ì†Œí†µì •ë³´ (êµ¬ê°„ë³„-ì²¨ë‘ì‹œë³„).csv',
                'description': 'ì›”ë³„ êµí†µì†Œí†µ ì •ë³´'
            },
            'gov_charging_service': {
                'file': 'í•œêµ­ì „ë ¥ê³µì‚¬_ì „ê¸°ì°¨ì¶©ì „ì„œë¹„ìŠ¤ìš´ì˜ì‹œìŠ¤í…œ_ê³ ê°ì„¼í„° ìƒë‹´ ë‚´ì—­_20241231.csv',
                'description': 'í•œêµ­ì „ë ¥ê³µì‚¬ ì „ê¸°ì°¨ ì¶©ì „ì„œë¹„ìŠ¤ ìƒë‹´ë‚´ì—­'
            },
            'charging_facility_management': {
                'file': 'í•œêµ­í™˜ê²½ê³µë‹¨_ì „ê¸°ì°¨ ì¶©ì „ì†Œ ìœ„ì¹˜ ë° ìš´ì˜ì •ë³´(ì¶©ì „ì†Œ ID í¬í•¨)_20230531.csv',
                'description': 'í•œêµ­í™˜ê²½ê³µë‹¨ ì „ê¸°ì°¨ ì¶©ì „ì†Œ ìœ„ì¹˜ ë° ìš´ì˜ ì •ë³´'
            }
        }
        
        # í•„ìˆ˜ ë°ì´í„°ì…‹ ë¡œë”©
        for dataset_name, config in dataset_configs.items():
            self._load_dataset(dataset_name, config, required=True)
        
        # ì„ íƒì  ë°ì´í„°ì…‹ ë¡œë”©
        for dataset_name, config in optional_datasets.items():
            self._load_dataset(dataset_name, config, required=False)
        
        self._print_loading_summary()
        return self.datasets
    
    def _load_dataset(self, dataset_name, config, required=True):
        """ê°œë³„ ë°ì´í„°ì…‹ì„ ë¡œë”©í•©ë‹ˆë‹¤."""
        print(f"ğŸ”„ ë¡œë”© ì¤‘: {dataset_name}")
        print()
        print("=" * 60)
        print(f"ğŸ“Š {config['description']}")
        print("=" * 60)
        
        file_path = self.data_dir / config['file']
        
        if not file_path.exists():
            if required:
                print(f"âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                print(f"âŒ {dataset_name} ë¡œë”© ì‹¤íŒ¨")
            else:
                print(f"âš ï¸ ì„ íƒì  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                print(f"âš ï¸ {dataset_name} ê±´ë„ˆëœ€ (ì„ íƒì  íŒŒì¼)")
            print()
            return None
        
        try:
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë¡œë”©
            if file_path.suffix.lower() in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path)
            elif file_path.suffix.lower() == '.csv':
                # ì¸ì½”ë”© ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë‹¤ì¤‘ ì‹œë„
                df = self._load_csv_with_encoding(file_path)
            else:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_path.suffix}")
                print(f"âŒ {dataset_name} ë¡œë”© ì‹¤íŒ¨")
                print()
                return None
            
            if df is None:
                print(f"âŒ {dataset_name} ë¡œë”© ì‹¤íŒ¨")
                print()
                return None
            
            print(f"ğŸ“ íŒŒì¼ëª…: {file_path}")
            print(f"ğŸ“ ë°ì´í„° í¬ê¸°: {df.shape[0]:,}í–‰ Ã— {df.shape[1]}ì—´")
            print()
            print("ğŸ” ì»¬ëŸ¼ ì •ë³´:")
            print(df.info())
            print()
            print("ğŸ“‹ ì²« 5í–‰ ë°ì´í„°:")
            print(df.head())
            print()
            print("ğŸ”¢ ê¸°ë³¸ í†µê³„:")
            print(df.describe())
            
            self.datasets[dataset_name] = df
            print(f"âœ… {dataset_name} ë¡œë”© ì„±ê³µ")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"âŒ {dataset_name} ë¡œë”© ì‹¤íŒ¨")
        
        print()
    
    def _load_csv_with_encoding(self, file_path):
        """ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ì„ ë¡œë”© ì‹œë„í•©ë‹ˆë‹¤."""
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig', 'latin1']
        
        for encoding in encodings:
            try:
                print(f"ğŸ”„ ì¸ì½”ë”© ì‹œë„: {encoding}")
                df = pd.read_csv(file_path, encoding=encoding)
                print(f"âœ… ì¸ì½”ë”© ì„±ê³µ: {encoding}")
                return df
            except UnicodeDecodeError:
                print(f"âŒ ì¸ì½”ë”© ì‹¤íŒ¨: {encoding}")
                continue
            except Exception as e:
                print(f"âŒ ê¸°íƒ€ ì˜¤ë¥˜ ({encoding}): {e}")
                continue
        
        print("âŒ ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨")
        return None
    
    def _print_loading_summary(self):
        """ë¡œë”© ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print("=" * 60)
        print("ğŸ“‹ ë°ì´í„° ë¡œë”© ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        total_datasets = 10  # ì „ì²´ ì‹œë„í•œ ë°ì´í„°ì…‹ ìˆ˜
        successful = len(self.datasets)
        failed = total_datasets - successful
        
        print(f"ì´ ë°ì´í„°ì…‹: {total_datasets}ê°œ")
        print(f"ë¡œë”© ì„±ê³µ: {successful}ê°œ")
        print(f"ë¡œë”© ì‹¤íŒ¨: {failed}ê°œ")
        print()
        
        if self.datasets:
            print("âœ… ì„±ê³µì ìœ¼ë¡œ ë¡œë”©ëœ ë°ì´í„°ì…‹:")
            for name, df in self.datasets.items():
                print(f"   â€¢ {name}: {df.shape[0]:,}í–‰ Ã— {df.shape[1]}ì—´")
        print()
        
        if failed > 0:
            failed_datasets = []
            all_possible = [
                'ev_charging_service', 'charging_load_hourly', 'ev_registration_monthly',
                'commercial_facilities', 'public_parking', 'charging_stations_202501',
                'charging_stations_202502', 'charging_stations_202503', 
                'gov_charging_service', 'charging_facility_management'
            ]
            failed_datasets = [name for name in all_possible if name not in self.datasets]
            
            if failed_datasets:
                print("âŒ ë¡œë”© ì‹¤íŒ¨í•œ ë°ì´í„°ì…‹:")
                for name in failed_datasets:
                    print(f"   â€¢ {name}")
        print()
        print("âœ… ëª¨ë“  ë°ì´í„° ë¡œë”© í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
    
    def get_dataset(self, dataset_name):
        """íŠ¹ì • ë°ì´í„°ì…‹ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.datasets.get(dataset_name, None)
    
    def get_all_datasets(self):
        """ëª¨ë“  ë¡œë”©ëœ ë°ì´í„°ì…‹ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.datasets

# ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë“¤
def load_all_datasets():
    """ëª¨ë“  ë°ì´í„°ì…‹ì„ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    loader = DataLoader()
    return loader.load_all_datasets()

def create_data_loader():
    """DataLoader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    return DataLoader()